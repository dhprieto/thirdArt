{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading, cleaningm, scaling, enconding and spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re \n",
    "\n",
    "def fullRead(pathToTable, sep, anthro = False):\n",
    "\n",
    "  df_renamed = pd.read_csv(pathToTable, sep = sep, encoding = \"latin_1\")\n",
    "  \n",
    "  df_name = re.sub(\"_ord.csv\",\"\",(re.sub(\"data/\", \"\" ,pathToTable)))\n",
    "  # reading and merging    \n",
    "  \n",
    "  if anthro == True:\n",
    "    df_anthro = pd.read_csv(\"data/chronicAnthropometricCardiovascularData.csv\", sep=\";\", decimal=\",\")\n",
    "    df_renamed = df_renamed.merge(df_anthro)\n",
    "\n",
    "    # separating by time moment and renaming\n",
    "\n",
    "    df_renamed[\"Weight\"] = \"\"\n",
    "    df_renamed[\"BMI\"] = \"\"\n",
    "    df_renamed[\"Fat\"] = \"\"\n",
    "    df_renamed[\"CVRI\"] = \"\"\n",
    "    df_renamed[\"Bpmin\"] = \"\"\n",
    "    df_renamed[\"Bpmax\"] = \"\"\n",
    "    df_renamed[\"Frec\"] = \"\"\n",
    "\n",
    "    for i in range(len(df_renamed)):\n",
    "\n",
    "        if df_renamed.loc[i][\"Time\"] == \"Initial\":\n",
    "            df_renamed.loc[i,\"Weight\"] = df_renamed.loc[i][\"Peso inicial\"]\n",
    "            df_renamed.loc[i,\"BMI\"] = df_renamed.loc[i][\"IMC Inicial\"]\n",
    "            df_renamed.loc[i,\"Fat\"] = df_renamed.loc[i][\"Grasa inicial\"]\n",
    "            df_renamed.loc[i,\"CVRI\"] = df_renamed.loc[i][\"IRCV inicial\"] \n",
    "            df_renamed.loc[i,\"Bpmin\"] = df_renamed.loc[i][\"Bpmin inicial\"] \n",
    "            df_renamed.loc[i,\"Bpmax\"] = df_renamed.loc[i][\"Bpmax inicial\"] \n",
    "            df_renamed.loc[i,\"Frec\"] = df_renamed.loc[i][\"Frec inicial\"] \n",
    "                \n",
    "        if df_renamed.loc[i][\"Time\"] == \"Final\":\n",
    "        \n",
    "            df_renamed.loc[i,\"Weight\"] = df_renamed.loc[i][\"Peso final\"]\n",
    "            df_renamed.loc[i,\"BMI\"] = df_renamed.loc[i][\"IMC Final\"]\n",
    "            df_renamed.loc[i,\"Fat\"] = df_renamed.loc[i][\"Grasa final\"]\n",
    "            df_renamed.loc[i,\"CVRI\"] = df_renamed.loc[i][\"IRCV Final\"] \n",
    "            df_renamed.loc[i,\"Bpmin\"] = df_renamed.loc[i][\"Bpmin final\"] \n",
    "            df_renamed.loc[i,\"Bpmax\"] = df_renamed.loc[i][\"Bpmax final\"] \n",
    "            df_renamed.loc[i,\"Frec\"] = df_renamed.loc[i][\"Frec final\"] \n",
    "        \n",
    "    df_renamed.drop(columns = [\"Peso inicial\", \"Peso final\", \"Delta Peso\", \"Talla\", \"IMC Inicial\", \"IMC Final\", \"Delta IMC\", \"Grasa inicial\", \"Grasa final\", \"Delta Grasa\", \"IRCV Final\", \"IRCV inicial\", \"Bpmin final\", \"Bpmin inicial\", \"Bpmax final\", \"Bpmax inicial\", \"Frec final\", \"Frec inicial\",], inplace=True )\n",
    "  \n",
    "  df_renamed.drop(columns = [\"Unnamed: 0\", \"grouping\"], inplace=True )\n",
    "  df_renamed.fillna(0, inplace=True)\n",
    "  return (df_renamed, df_name)\n",
    "\n",
    "def scaling(df_read):\n",
    "   \n",
    "   scaler = preprocessing.MinMaxScaler()\n",
    "   numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n",
    "   df_read[numCols] = scaler.fit_transform(df_read[numCols])\n",
    "   return df_read\n",
    "\n",
    "def encodingSplitting(df):\n",
    "  df = pd.get_dummies(df, columns = [\"Sweetener\", \"Sex\", \"Time\"], drop_first=False)\n",
    "  X_met, y_met = df[df[\"Time_Initial\"] == 1].drop([\"numVol\", \"Time_Initial\", \"Time_Final\"], axis=1), df[df[\"Time_Final\"] == 1].drop(['Sweetener_SA', 'Sweetener_ST','Sweetener_SU', 'Sex_MAN', 'Sex_WOMAN', 'Time_Final', 'Time_Initial','numVol', 'Weight','BMI', 'Fat', 'CVRI', 'Bpmin', 'Bpmax', 'Frec'], axis = 1)\n",
    "  X_metTrain, X_metTest, y_metTrain, y_metTest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "  X_full, y_full = df[df[\"Time_Initial\"] == 1].drop([\"numVol\", \"Time_Initial\", \"Time_Final\"], axis=1), df[df[\"Time_Final\"] == 1].drop(['numVol','Sweetener_SA', 'Sweetener_ST','Sweetener_SU','Time_Final', 'Time_Initial'], axis = 1)\n",
    "  X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = train_test_split(X_full, y_full, test_size=0.3, random_state=42)\n",
    "\n",
    "  return(X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest)\n",
    "\n",
    "\n",
    "#df_PF = pd.get_dummies(scaling(fullRead(\"data/plasmFlav_ord.csv\",  sep = \",\", anthro= True)), columns = [\"Sweetener\", \"Sex\", \"Time\"], drop_first=False)\n",
    "#df_PA = scaling(fullRead(\"data/plasmAnt_ord.csv\",  sep = \",\", anthro= True))\n",
    "#df_UF = scaling(fullRead(\"data/urineFlav_ord.csv\",  sep = \",\", anthro= True))\n",
    "#df_UA = scaling(fullRead(\"data/urineAnt_ord.csv\",  sep = \",\", anthro= True))\n",
    "#X_test.to_csv(\"X_met_test_urineAnt.csv\", index=False)\n",
    "#X_fulltest.to_csv(\"X_full_test_urineAnt.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_met' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dres2\\Documents\\repositories\\thirdArt\\main.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_met\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_met' is not defined"
     ]
    }
   ],
   "source": [
    "X_met"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# import pickle\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "# define model\n",
    "\n",
    "def randomForestReg(df, df_name, met = True):\n",
    "    \n",
    "    if (met):\n",
    "        \n",
    "        X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = encodingSplitting(df)\n",
    "\n",
    "        model = RandomForestRegressor()\n",
    "\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "        grid_search.fit(X_metTrain, y_metTrain)\n",
    "        best_grid = grid_search.best_estimator_\n",
    "        # define the evaluation procedure\n",
    "        cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "        # evaluate the model and collect the scores\n",
    "        n_scores = cross_val_score(best_grid, X_metTest, y_metTest, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "        # force the scores to be positive\n",
    "        n_scores = np.absolute(n_scores)\n",
    "        # summarize performance\n",
    "\n",
    "        #filename = 'rf_met_plasmAnt.pkl'\n",
    "        #with open(filename, 'wb') as file:\n",
    "        #    pickle.dump(grid_search.best_estimator_, file)\n",
    "\n",
    "        print('Only Metabolic model ' + df_name + ': MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "        MAE = (np.mean(n_scores), np.std(n_scores))\n",
    "        return(best_grid, MAE)\n",
    "\n",
    "    else:\n",
    "            \n",
    "        X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = encodingSplitting(df)\n",
    "\n",
    "        model = RandomForestRegressor()\n",
    "\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = param_grid, \n",
    "                        cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "        grid_search.fit(X_fullTrain, y_fullTrain)\n",
    "        best_grid = grid_search.best_estimator_\n",
    "        # define the evaluation procedure\n",
    "        cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "        # evaluate the model and collect the scores\n",
    "        n_scores = cross_val_score(best_grid, X_fullTest, y_fullTest, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "        # force the scores to be positive\n",
    "        n_scores = np.absolute(n_scores)\n",
    "        # summarize performance\n",
    "\n",
    "        #filename = 'rf_met_plasmAnt.pkl'\n",
    "        #with open(filename, 'wb') as file:\n",
    "        #    pickle.dump(grid_search.best_estimator_, file)\n",
    "\n",
    "        print('Full model ' + df_name + ': MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "        MAE = (np.mean(n_scores), np.std(n_scores))\n",
    "        return(best_grid, MAE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Only Metabolic plasmFlav: MAE: 0.053 (0.019)\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Full model plasmFlav: MAE: 0.094 (0.010)\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Only Metabolic plasmAnt: MAE: 0.053 (0.020)\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Full model plasmAnt: MAE: 0.123 (0.010)\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Only Metabolic urineFlav: MAE: 0.054 (0.020)\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Full model urineFlav: MAE: 0.091 (0.013)\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Only Metabolic urineAnt: MAE: 0.054 (0.020)\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Full model urineAnt: MAE: 0.093 (0.008)\n"
     ]
    }
   ],
   "source": [
    "paths = [\"plasmFlav_ord.csv\", \"plasmAnt_ord.csv\", \"urineFlav_ord.csv\", \"urineAnt_ord.csv\"]\n",
    "paths = [\"data/\" + s for s in paths]\n",
    "\n",
    "resultsModelsRF = {}\n",
    "resultsScoresRF = {}\n",
    "\n",
    "for path in paths:\n",
    "    df, df_name = fullRead(path, sep = \",\", anthro = True)\n",
    "    resultsModelsRF[\"modelRFMet{0}\".format(df_name)], resultsScoresRF[\"modelRFMet{0}\".format(df_name)] = randomForestReg(scaling(df), df_name, met = True)\n",
    "    resultsModelsRF[\"modelRFFull{0}\".format(df_name)], resultsScoresRF[\"modelRFFull{0}\".format(df_name)] = randomForestReg(scaling(df), df_name, met = False)\n",
    "\n",
    "\n",
    "\n",
    "#modelRFMet = randomForestReg(scaling(fullRead(\"data/plasmFlav_ord.csv\",  sep = \",\", anthro= True)[0]), met = True)\n",
    "#modelRFFull = randomForestReg(scaling(fullRead(\"data/plasmFlav_ord.csv\",  sep = \",\", anthro= True)), met = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modelRFMetdata/plasmFlav_ord.csv': (0.05305571020940363,\n",
       "  0.019355957726905838),\n",
       " 'modelRFFulldata/plasmFlav_ord.csv': (0.09350444273592906,\n",
       "  0.00974506016507601),\n",
       " 'modelRFMetdata/plasmAnt_ord.csv': (0.05349754173439036, 0.02006719966152714),\n",
       " 'modelRFFulldata/plasmAnt_ord.csv': (0.12341770738231064,\n",
       "  0.010457016301911155),\n",
       " 'modelRFMetdata/urineFlav_ord.csv': (0.0537300603471775,\n",
       "  0.019774406267297245),\n",
       " 'modelRFFulldata/urineFlav_ord.csv': (0.09082384827131884,\n",
       "  0.013140742577472485),\n",
       " 'modelRFMetdata/urineAnt_ord.csv': (0.05414192453820145,\n",
       "  0.019888635239077763),\n",
       " 'modelRFFulldata/urineAnt_ord.csv': (0.09300592377394583,\n",
       "  0.007926720376069184)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsScores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiLayerPerceptron Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp for multi-output regression\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold, GridSearchCV\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "# fix random seed for reproducibility\n",
    "\n",
    "def MLPReg (df, df_name, met):\n",
    "    \n",
    "    if (met):\n",
    "        seed = 7\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "        X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = encodingSplitting(df)\n",
    "\n",
    "\n",
    "        epochs = [10, 50, 100]\n",
    "        batch_size = [10, 20, 40, 60, 80, 100]\n",
    "\n",
    "        param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "        # get the model\n",
    "        def get_model(n_inputs, n_outputs):\n",
    "            model_nn = Sequential()\n",
    "            model_nn.add(Dense(64, input_shape=(n_inputs,),activation=\"relu\"))\n",
    "            model_nn.add(Dropout(0.5))\n",
    "            model_nn.add(Dense(32, activation=\"relu\"))\n",
    "            model_nn.add(Dropout(0.5))\n",
    "            model_nn.add(Dense(n_outputs, activation='linear'))\n",
    "            model_nn.compile(loss='mae', optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "            return model_nn\n",
    "        \n",
    "        # evaluate a model using repeated k-fold cross-validation\n",
    "        def evaluate_model(X, y):\n",
    "            results = list()\n",
    "            n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "            # define evaluation procedure\n",
    "            cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            # define modeld\n",
    "            model_nn = KerasRegressor(model = get_model(n_inputs, n_outputs), optimizer=tf.keras.optimizers.Adam(), verbose=0)\n",
    "            # fit model\n",
    "            grid = GridSearchCV(estimator=model_nn, param_grid=param_grid, n_jobs=-1, cv=3, verbose=0)\n",
    "            grid_result = grid.fit(X_train, y_train) # evaluate model on test set\n",
    "            # summarize results\n",
    "            best_grid = grid_result.best_estimator_\n",
    "            # define the evaluation procedure\n",
    "            cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "            # evaluate the model and collect the scores\n",
    "            n_scores = cross_val_score(best_grid, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "            # force the scores to be positive\n",
    "            n_scores = np.absolute(n_scores)\n",
    "\n",
    "            # store the model\n",
    "            # filename = 'mlp_met_plasmAnt.pkl'\n",
    "            # with open(filename, 'wb') as file:\n",
    "            #    pickle.dump(grid_result.best_estimator_, file)\n",
    "\n",
    "            # summarize performance\n",
    "            print('Only Metabolic model ' + df_name +'MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "            MAE = (np.mean(n_scores), np.std(n_scores))\n",
    "            return(best_grid, MAE)\n",
    "            # evaluate model\n",
    "            \n",
    "        modelMLP, MAE = evaluate_model(X_met, y_met)\n",
    "    \n",
    "    else:\n",
    "        seed = 7\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "        X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = encodingSplitting(df)\n",
    "\n",
    "\n",
    "        epochs = [10, 50, 100]\n",
    "        batch_size = [10, 20, 40, 60, 80, 100]\n",
    "\n",
    "        param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "        # get the model\n",
    "        def get_model(n_inputs, n_outputs):\n",
    "            model_nn = Sequential()\n",
    "            model_nn.add(Dense(64, input_shape=(n_inputs,),activation=\"relu\"))\n",
    "            model_nn.add(Dropout(0.5))\n",
    "            model_nn.add(Dense(32, activation=\"relu\"))\n",
    "            model_nn.add(Dropout(0.5))\n",
    "            model_nn.add(Dense(n_outputs, activation='linear'))\n",
    "            model_nn.compile(loss='mae', optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "            return model_nn\n",
    "        \n",
    "        # evaluate a model using repeated k-fold cross-validation\n",
    "        def evaluate_model(X, y):\n",
    "            results = list()\n",
    "            n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "            # define evaluation procedure\n",
    "            cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            # define modeld\n",
    "            model_nn = KerasRegressor(model = get_model(n_inputs, n_outputs), optimizer=tf.keras.optimizers.Adam(), verbose=0)\n",
    "            # fit model\n",
    "            grid = GridSearchCV(estimator=model_nn, param_grid=param_grid, n_jobs=-1, cv=3, verbose=0)\n",
    "            grid_result = grid.fit(X_train, y_train) # evaluate model on test set\n",
    "            # summarize results\n",
    "            best_grid = grid_result.best_estimator_\n",
    "            # define the evaluation procedure\n",
    "            cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "            # evaluate the model and collect the scores\n",
    "            n_scores = cross_val_score(best_grid, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "            # force the scores to be positive\n",
    "            n_scores = np.absolute(n_scores)\n",
    "\n",
    "            # store the model\n",
    "            # filename = 'mlp_met_plasmAnt.pkl'\n",
    "            # with open(filename, 'wb') as file:\n",
    "            #    pickle.dump(grid_result.best_estimator_, file)\n",
    "\n",
    "            # summarize performance\n",
    "            print('Full model ' + df_name + 'MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "            MAE = (np.mean(n_scores), np.std(n_scores))\n",
    "            return(best_grid, MAE)\n",
    "            # evaluate model\n",
    "            \n",
    "        modelMLP, MAE = evaluate_model(X_full, y_full)    \n",
    "    return (modelMLP, MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.054 (0.022)\n",
      "MAE: 0.092 (0.014)\n",
      "MAE: 0.096 (0.019)\n",
      "MAE: 0.111 (0.016)\n",
      "MAE: 0.051 (0.021)\n",
      "MAE: 0.080 (0.012)\n",
      "MAE: 0.071 (0.019)\n",
      "MAE: 0.087 (0.014)\n"
     ]
    }
   ],
   "source": [
    "paths = [\"plasmFlav_ord.csv\", \"plasmAnt_ord.csv\", \"urineFlav_ord.csv\", \"urineAnt_ord.csv\"]\n",
    "paths = [\"data/\" + s for s in paths]\n",
    "\n",
    "resultsModelsMLP = {}\n",
    "resultsScoresMLP = {}\n",
    "\n",
    "for path in paths:\n",
    "    df, df_name = fullRead(path, sep = \",\", anthro = True)\n",
    "    resultsModelsMLP[\"modelMLPMet{0}\".format(df_name)], resultsScoresMLP[\"modelMLPMet{0}\".format(df_name)] = MLPReg(scaling(df), df_name, met = True)\n",
    "    resultsModelsMLP[\"modelMLPFull{0}\".format(df_name)], resultsScoresMLP[\"modelMLPFull{0}\".format(df_name)] = MLPReg(scaling(df), df_name, met = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modelMLPMetdata/plasmFlav_ord.csv': (0.053883654018792346,\n",
       "  0.02160481184928749),\n",
       " 'modelMLPFulldata/plasmFlav_ord.csv': (0.09196652860139162,\n",
       "  0.01363769383341583),\n",
       " 'modelMLPMetdata/plasmAnt_ord.csv': (0.09566204001361353,\n",
       "  0.01885550970993914),\n",
       " 'modelMLPFulldata/plasmAnt_ord.csv': (0.11069668151990246,\n",
       "  0.015924388417305948),\n",
       " 'modelMLPMetdata/urineFlav_ord.csv': (0.0513886545338527,\n",
       "  0.020606704620211604),\n",
       " 'modelMLPFulldata/urineFlav_ord.csv': (0.07958265553535816,\n",
       "  0.011993007172429588),\n",
       " 'modelMLPMetdata/urineAnt_ord.csv': (0.07092841537529868,\n",
       "  0.01949563980533962),\n",
       " 'modelMLPFulldata/urineAnt_ord.csv': (0.0870458449412254,\n",
       "  0.014102588320115112)}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsScoresMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score, GridSearchCV\n",
    "\n",
    "def XGBReg (df, df_name, met):\n",
    "\n",
    "    X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = encodingSplitting(df)\n",
    "\n",
    "    if (met):\n",
    "        \n",
    "        xgbReg = XGBRegressor()\n",
    "\n",
    "        param_grid = {'max_depth'        : [None, 1, 3, 5, 10, 20],\n",
    "                    'subsample'        : [0.5, 1],\n",
    "                    'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "                    'booster'          : ['gbtree', 'gblinear', 'dart']\n",
    "                    }\n",
    "\n",
    "\n",
    "        grid_search = GridSearchCV(estimator = xgbReg, param_grid = param_grid, cv= 3, n_jobs=-1,\n",
    "                                verbose=2)\n",
    "\n",
    "        grid_search.fit(X_metTrain, y_metTrain)\n",
    "        best_grid = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "        cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "        n_scores = cross_val_score(best_grid, X_metTest, y_metTest,  scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "        n_scores = np.absolute(n_scores)\n",
    "\n",
    "        print(\"Only metabolic model \" + df_name +' MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "        MAE = (np.mean(n_scores), np.std(n_scores))\n",
    "        return(best_grid, MAE)\n",
    "    \n",
    "    else:\n",
    "        xgbReg = XGBRegressor()\n",
    "\n",
    "        param_grid = {'max_depth'        : [None, 1, 3, 5, 10, 20],\n",
    "                    'subsample'        : [0.5, 1],\n",
    "                    'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "                    'booster'          : ['gbtree', 'gblinear', 'dart']\n",
    "                    }\n",
    "\n",
    "\n",
    "        grid_search = GridSearchCV(estimator = xgbReg, param_grid = param_grid, cv= 3, n_jobs=-1,\n",
    "                                verbose=2)\n",
    "\n",
    "        grid_search.fit(X_fullTrain, y_fullTrain)\n",
    "        best_grid = grid_search.best_estimator_\n",
    "\n",
    "        cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "        n_scores = cross_val_score(best_grid, X_fullTest, y_fullTest,  scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "        n_scores = np.absolute(n_scores)\n",
    "\n",
    "        print(\"Full model \"+ df_name + ' MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "        MAE = (np.mean(n_scores), np.std(n_scores))\n",
    "        return(best_grid, MAE)        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Only metabolic model plasmFlav MAE: 0.066 (0.020)\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Full model plasmFlav MAE: 0.104 (0.009)\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Only metabolic model plasmAnt MAE: 0.066 (0.020)\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dres2\\Documents\\repositories\\thirdArt\\main.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X53sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df, df_name \u001b[39m=\u001b[39m fullRead(path, sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, anthro \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X53sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m resultsModelsXGB[\u001b[39m\"\u001b[39m\u001b[39mmodelXGBMet\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(df_name)], resultsScoresXGB[\u001b[39m\"\u001b[39m\u001b[39mmodelXGBMet\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(df_name)] \u001b[39m=\u001b[39m XGBReg(scaling(df), df_name, met \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X53sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m resultsModelsXGB[\u001b[39m\"\u001b[39m\u001b[39mmodelXGBFull\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(df_name)], resultsScoresXGB[\u001b[39m\"\u001b[39m\u001b[39mmodelXGBFull\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(df_name)] \u001b[39m=\u001b[39m XGBReg(scaling(df), df_name, met \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\dres2\\Documents\\repositories\\thirdArt\\main.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X53sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m param_grid \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m        : [\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m20\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X53sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39msubsample\u001b[39m\u001b[39m'\u001b[39m        : [\u001b[39m0.5\u001b[39m, \u001b[39m1\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X53sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m    : [\u001b[39m0.001\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m0.1\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X53sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mbooster\u001b[39m\u001b[39m'\u001b[39m          : [\u001b[39m'\u001b[39m\u001b[39mgbtree\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgblinear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdart\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X53sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m             }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X53sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator \u001b[39m=\u001b[39m xgbReg, param_grid \u001b[39m=\u001b[39m param_grid, cv\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X53sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m                         verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X53sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m grid_search\u001b[39m.\u001b[39mfit(X_fullTrain, y_fullTrain)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X53sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m best_grid \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X53sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m cv \u001b[39m=\u001b[39m RepeatedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_repeats\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39mresult(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "paths = [\"plasmFlav_ord.csv\", \"plasmAnt_ord.csv\", \"urineFlav_ord.csv\", \"urineAnt_ord.csv\"]\n",
    "paths = [\"data/\" + s for s in paths]\n",
    "\n",
    "resultsModelsXGB = {}\n",
    "resultsScoresXGB = {}\n",
    "\n",
    "for path in paths:\n",
    "    df, df_name = fullRead(path, sep = \",\", anthro = True)\n",
    "    resultsModelsXGB[\"modelXGBMet{0}\".format(df_name)], resultsScoresXGB[\"modelXGBMet{0}\".format(df_name)] = XGBReg(scaling(df), df_name, met = True)\n",
    "    resultsModelsXGB[\"modelXGBFull{0}\".format(df_name)], resultsScoresXGB[\"modelXGBFull{0}\".format(df_name)] = XGBReg(scaling(df), df_name, met = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modelXGBMetplasmFlav': (0.06566482327975234, 0.020082282056815344),\n",
       " 'modelXGBFullplasmFlav': (0.05899397690121679, 0.01190496238480627),\n",
       " 'modelXGBMetplasmAnt': (0.06566482327975234, 0.020082282056815344),\n",
       " 'modelXGBFullplasmAnt': (0.12116975738171971, 0.01455740739431039),\n",
       " 'modelXGBMeturineFlav': (0.06566482327975234, 0.020082282056815344),\n",
       " 'modelXGBFullurineFlav': (0.08880958387223581, 0.02758939798969107),\n",
       " 'modelXGBMeturineAnt': (0.06566482327975234, 0.020082282056815344),\n",
       " 'modelXGBFullurineAnt': (0.0778253075732373, 0.010167032490283107)}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsScoresXGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectFromModel method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=110, max_features=2, min_samples_leaf=3,\n",
       "                      min_samples_split=12, n_estimators=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=110, max_features=2, min_samples_leaf=3,\n",
       "                      min_samples_split=12, n_estimators=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=110, max_features=2, min_samples_leaf=3,\n",
       "                      min_samples_split=12, n_estimators=300)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsModels[\"modelRFMetdata/plasmFlav_ord.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['E', 'E.S', 'Total.E', 'HE.G', 'N.G', 'Weight', 'BMI', 'Fat', 'CVRI',\n",
      "       'Bpmin', 'Bpmax', 'Frec', 'Sweetener_SA', 'Sweetener_ST',\n",
      "       'Sweetener_SU', 'Sex_MAN', 'Sex_WOMAN'],\n",
      "      dtype='object')\n",
      "RandomForestRegressor(max_depth=110, max_features=2, min_samples_leaf=3,\n",
      "                      min_samples_split=12, n_estimators=300)\n",
      "Index(['E', 'E.S', 'Total.E', 'HE.G', 'N.G', 'Weight', 'BMI', 'Fat', 'CVRI',\n",
      "       'Bpmin', 'Bpmax', 'Frec', 'Sweetener_SA', 'Sweetener_ST',\n",
      "       'Sweetener_SU', 'Sex_MAN', 'Sex_WOMAN'],\n",
      "      dtype='object')\n",
      "RandomForestRegressor(max_depth=110, max_features=2, min_samples_leaf=3,\n",
      "                      min_samples_split=12, n_estimators=300)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 16 features, but RandomForestRegressor is expecting 17 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dres2\\Documents\\repositories\\thirdArt\\main.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#Y105sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m select_X_test \u001b[39m=\u001b[39m selection\u001b[39m.\u001b[39mtransform(X_metTest)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#Y105sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#thresholds\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#Y105sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m y_pred \u001b[39m=\u001b[39m selection_model\u001b[39m.\u001b[39mpredict(select_X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#Y105sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m predictions \u001b[39m=\u001b[39m [value \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m y_pred]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#Y105sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m mae \u001b[39m=\u001b[39m mean_absolute_error(y_metTest, predictions)\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:984\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    982\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    983\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 984\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    986\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    987\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, dtype\u001b[39m=\u001b[39mDTYPE, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:626\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 626\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39mreset)\n\u001b[0;32m    628\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 415\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    416\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 16 features, but RandomForestRegressor is expecting 17 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "df, df_name = fullRead(\"data/plasmFlav_ord.csv\", sep = \",\", anthro = True)\n",
    "X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = encodingSplitting(df)\n",
    "\n",
    "model = resultsModels[\"modelRFMetdata/plasmFlav_ord.csv\"] # model PF_met\n",
    "\n",
    "#model.fit(X_metTrain, y_metTrain)\n",
    "\n",
    "thresholds = np.sort(model.feature_importances_)\n",
    "results = pd.DataFrame()\n",
    "for thresh in thresholds:\n",
    " # select features using threshold\n",
    " selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    " feature_idx = selection.get_support()\n",
    " print(X_metTrain.columns[feature_idx])\n",
    " select_X_train = selection.transform(X_metTrain)\n",
    " # train model\n",
    " selection_model = model\n",
    " selection_model.fit(select_X_train, y_metTrain)\n",
    " print (selection_model)\n",
    " # eval model\n",
    " select_X_test = selection.transform(X_metTest)\n",
    " #thresholds\n",
    " y_pred = selection_model.predict(select_X_test)\n",
    " predictions = [value for value in y_pred]\n",
    " mae = mean_absolute_error(y_metTest, predictions)\n",
    " result1 = pd.DataFrame({\"thresh\": thresh, \"n\":select_X_train.shape[1], \"MAE\":mae}, index = [30 - select_X_train.shape[1]])\n",
    " results = pd.concat([results, result1])\n",
    " #print(\"Thresh=%.3f, n=%d, MAE: %.4f\" % (thresh, select_X_train.shape[1], accuracy))\n",
    "\n",
    "print(results)\n",
    "\n",
    "thresholdSelected = results.sort_values(by= \"MAE\", ascending = True).head(n=1)[\"thresh\"]\n",
    "\n",
    "### Si hay que reentrenar:\n",
    "# select features using threshold\n",
    "selection = SelectFromModel(model, threshold=thresholdSelected, prefit=True)\n",
    "feature_idx = selection.get_support()\n",
    "print(X_metTrain.columns[feature_idx])\n",
    "select_X_train = selection.transform(X_metTrain)\n",
    "# train model\n",
    "model.fit(select_X_train, y_metTrain)\n",
    "# eval model\n",
    "select_X_test = selection.transform(X_metTest)\n",
    "y_pred = selection_model.predict(select_X_test)\n",
    "predictions = [value for value in y_pred]\n",
    "mae = mean_absolute_error(y_metTest, predictions)\n",
    "result1 = pd.DataFrame({\"thresh\": thresh, \"n\":select_X_train.shape[1], \"MAE\":mae}, index = [30 - select_X_train.shape[1]])\n",
    "result1\n",
    "\n",
    "### Si ->NO<- hay que reentrenar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresh</th>\n",
       "      <th>n</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.007003</td>\n",
       "      <td>17</td>\n",
       "      <td>0.057547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010890</td>\n",
       "      <td>16</td>\n",
       "      <td>0.059614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.013178</td>\n",
       "      <td>15</td>\n",
       "      <td>0.058458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.017247</td>\n",
       "      <td>14</td>\n",
       "      <td>0.060473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.017888</td>\n",
       "      <td>13</td>\n",
       "      <td>0.056218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.022161</td>\n",
       "      <td>12</td>\n",
       "      <td>0.059634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.039065</td>\n",
       "      <td>11</td>\n",
       "      <td>0.058788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.056996</td>\n",
       "      <td>10</td>\n",
       "      <td>0.058360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.061445</td>\n",
       "      <td>9</td>\n",
       "      <td>0.059553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.066593</td>\n",
       "      <td>8</td>\n",
       "      <td>0.058089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.077221</td>\n",
       "      <td>7</td>\n",
       "      <td>0.054710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.078000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.059857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.082806</td>\n",
       "      <td>5</td>\n",
       "      <td>0.058776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.101111</td>\n",
       "      <td>4</td>\n",
       "      <td>0.062257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.102140</td>\n",
       "      <td>3</td>\n",
       "      <td>0.056693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.118331</td>\n",
       "      <td>2</td>\n",
       "      <td>0.067723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.127924</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      thresh   n       MAE\n",
       "13  0.007003  17  0.057547\n",
       "14  0.010890  16  0.059614\n",
       "15  0.013178  15  0.058458\n",
       "16  0.017247  14  0.060473\n",
       "17  0.017888  13  0.056218\n",
       "18  0.022161  12  0.059634\n",
       "19  0.039065  11  0.058788\n",
       "20  0.056996  10  0.058360\n",
       "21  0.061445   9  0.059553\n",
       "22  0.066593   8  0.058089\n",
       "23  0.077221   7  0.054710\n",
       "24  0.078000   6  0.059857\n",
       "25  0.082806   5  0.058776\n",
       "26  0.101111   4  0.062257\n",
       "27  0.102140   3  0.056693\n",
       "28  0.118331   2  0.067723\n",
       "29  0.127924   1  0.055581"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HE.G', 'N.G', 'Weight', 'BMI', 'Fat', 'Bpmin', 'Frec'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholdSelected = results.sort_values(by= \"MAE\", ascending = True).head(n=1)[\"thresh\"]\n",
    "\n",
    "# Si hay que reentrenar:\n",
    "\n",
    "\n",
    "\n",
    "# select features using threshold\n",
    "selection = SelectFromModel(model, threshold=thresholdSelected, prefit=True)\n",
    "feature_idx = selection.get_support()\n",
    "print(X_train.columns[feature_idx])\n",
    "select_X_train = selection.transform(X_train)\n",
    "# train model\n",
    "selection_model = RandomForestRegressor()\n",
    "selection_model.fit(select_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'if_delegate_has_method' from 'sklearn.utils.metaestimators' (c:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)\n",
      "\u001b[1;32mc:\\Users\\dres2\\Documents\\repositories\\thirdArt\\main.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39meli5\u001b[39;00m \n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meli5\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m PermutationImportance\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m perm_base \u001b[39m=\u001b[39m PermutationImportance(modelMLPMet, random_state \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfit(X, y)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\eli5\\__init__.py:13\u001b[0m\n",
      "\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mformatters\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n",
      "\u001b[0;32m      7\u001b[0m     format_as_html,\n",
      "\u001b[0;32m      8\u001b[0m     format_html_styles,\n",
      "\u001b[0;32m      9\u001b[0m     format_as_text,\n",
      "\u001b[0;32m     10\u001b[0m     format_as_dict,\n",
      "\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexplain\u001b[39;00m \u001b[39mimport\u001b[39;00m explain_weights, explain_prediction\n",
      "\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m explain_weights_sklearn, explain_prediction_sklearn\n",
      "\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtransform\u001b[39;00m \u001b[39mimport\u001b[39;00m transform_feature_names\n",
      "\u001b[0;32m     17\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\eli5\\sklearn\\__init__.py:3\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[39m# -*- coding: utf-8 -*-\u001b[39;00m\n",
      "\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n",
      "\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexplain_weights\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n",
      "\u001b[0;32m      4\u001b[0m     explain_weights_sklearn,\n",
      "\u001b[0;32m      5\u001b[0m     explain_linear_classifier_weights,\n",
      "\u001b[0;32m      6\u001b[0m     explain_linear_regressor_weights,\n",
      "\u001b[0;32m      7\u001b[0m     explain_rf_feature_importance,\n",
      "\u001b[0;32m      8\u001b[0m     explain_decision_tree,\n",
      "\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexplain_prediction\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n",
      "\u001b[0;32m     11\u001b[0m     explain_prediction_sklearn,\n",
      "\u001b[0;32m     12\u001b[0m     explain_prediction_linear_classifier,\n",
      "\u001b[0;32m     13\u001b[0m     explain_prediction_linear_regressor,\n",
      "\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39munhashing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n",
      "\u001b[0;32m     16\u001b[0m     InvertableHashingVectorizer,\n",
      "\u001b[0;32m     17\u001b[0m     FeatureUnhasher,\n",
      "\u001b[0;32m     18\u001b[0m     invert_hashing_and_fit,\n",
      "\u001b[0;32m     19\u001b[0m )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\eli5\\sklearn\\explain_weights.py:78\u001b[0m\n",
      "\u001b[0;32m     73\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meli5\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransform\u001b[39;00m \u001b[39mimport\u001b[39;00m transform_feature_names\n",
      "\u001b[0;32m     74\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meli5\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_feature_importances\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n",
      "\u001b[0;32m     75\u001b[0m     get_feature_importances_filtered,\n",
      "\u001b[0;32m     76\u001b[0m     get_feature_importance_explanation,\n",
      "\u001b[0;32m     77\u001b[0m )\n",
      "\u001b[1;32m---> 78\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpermutation_importance\u001b[39;00m \u001b[39mimport\u001b[39;00m PermutationImportance\n",
      "\u001b[0;32m     81\u001b[0m LINEAR_CAVEATS \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n",
      "\u001b[0;32m     82\u001b[0m \u001b[39mCaveats:\u001b[39m\n",
      "\u001b[0;32m     83\u001b[0m \u001b[39m1. Be careful with features which are not\u001b[39m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     90\u001b[0m \u001b[39m   classification result for most examples.\u001b[39m\n",
      "\u001b[0;32m     91\u001b[0m \u001b[39m\"\"\"\u001b[39m\u001b[39m.\u001b[39mlstrip()\n",
      "\u001b[0;32m     93\u001b[0m HASHING_CAVEATS \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n",
      "\u001b[0;32m     94\u001b[0m \u001b[39mFeature names are restored from their hashes; this is not 100\u001b[39m\u001b[39m%\u001b[39m\u001b[39m precise\u001b[39m\n",
      "\u001b[0;32m     95\u001b[0m \u001b[39mbecause collisions are possible. For known collisions possible feature names\u001b[39m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     99\u001b[0m \u001b[39mthe result is positive.\u001b[39m\n",
      "\u001b[0;32m    100\u001b[0m \u001b[39m\"\"\"\u001b[39m\u001b[39m.\u001b[39mlstrip()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\eli5\\sklearn\\permutation_importance.py:7\u001b[0m\n",
      "\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m check_cv\n",
      "\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetaestimators\u001b[39;00m \u001b[39mimport\u001b[39;00m if_delegate_has_method\n",
      "\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m check_array, check_random_state\n",
      "\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n",
      "\u001b[0;32m     10\u001b[0m     BaseEstimator,\n",
      "\u001b[0;32m     11\u001b[0m     MetaEstimatorMixin,\n",
      "\u001b[0;32m     12\u001b[0m     clone,\n",
      "\u001b[0;32m     13\u001b[0m     is_classifier\n",
      "\u001b[0;32m     14\u001b[0m )\n",
      "\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'if_delegate_has_method' from 'sklearn.utils.metaestimators' (c:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py)"
     ]
    }
   ],
   "source": [
    "import eli5 \n",
    "from eli5.sklearn import PermutationImportance\n",
    "perm_base = PermutationImportance(modelMLPMet, random_state = 1).fit(X, y)\n",
    "eli5.show_weights(perm_base, feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0905\n",
       "                \n",
       "                    &plusmn; 0.0166\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Sex\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0336\n",
       "                \n",
       "                    &plusmn; 0.0154\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Sweetener\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.83%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0169\n",
       "                \n",
       "                    &plusmn; 0.0053\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Weight\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0153\n",
       "                \n",
       "                    &plusmn; 0.0060\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BMI\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0080\n",
       "                \n",
       "                    &plusmn; 0.0031\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Fat\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "                    &plusmn; 0.0025\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                CVRI\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0026\n",
       "                \n",
       "                    &plusmn; 0.0016\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Bpmin\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0026\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Bpmax\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0024\n",
       "                \n",
       "                    &plusmn; 0.0019\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                VA.GS\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.50%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0022\n",
       "                \n",
       "                    &plusmn; 0.0016\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                CA\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.55%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0021\n",
       "                \n",
       "                    &plusmn; 0.0022\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                VA.SS\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.62%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0020\n",
       "                \n",
       "                    &plusmn; 0.0028\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                VA.S\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0019\n",
       "                \n",
       "                    &plusmn; 0.0014\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                TFA.S\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                DHPAA.GS\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.98%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0013\n",
       "                \n",
       "                    &plusmn; 0.0016\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                CA.G\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.14%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0010\n",
       "                \n",
       "                    &plusmn; 0.0041\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                DHPAA.SS\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Total.CA\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.46%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                VA.GG\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                DHPAA.GG\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Total.TFA\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.53%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 8 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5 \n",
    "from eli5.sklearn import PermutationImportance\n",
    "perm_base = PermutationImportance(uwu.best_estimator_, random_state = 1).fit(X_fulltrain, y_fulltrain)\n",
    "eli5.show_weights(perm_base, feature_names = X_fulltrain.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full parameters gridsearch\n",
    "# DONT EXECUTE\n",
    "'''\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "weight_constraint = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, optimizer=optimizer, optimizer__learning_rate=learn_rate, optimizer__momentum=momentum,\n",
    "                  model__init_mode=init_mode, model__activation=activation, model__dropout_rate=dropout_rate, model__weight_constraint=weight_constraint)\n",
    "\n",
    "# get the model\n",
    "def get_model(n_inputs, n_outputs, dropout_rate, weight_constraint, activation=\"relu\", init_mode='uniform'):\n",
    "    model_nn = Sequential()\n",
    "    model_nn.add(Dense(64, input_shape=(X.shape[1],),activation=activation, kernel_initializer=init_mode, kernel_constraint=MaxNorm(weight_constraint)))\n",
    "    model_nn.add(Dropout(dropout_rate))\n",
    "    model_nn.add(Dense(32, activation=activation, kernel_initializer=init_mode))\n",
    "    model_nn.add(Dropout(dropout_rate))\n",
    "    model_nn.add(Dense(y.shape[1], activation='linear', kernel_initializer=init_mode))\n",
    "    return model_nn\n",
    " \n",
    "# evaluate a model using repeated k-fold cross-validation\n",
    "def evaluate_model(X, y):\n",
    " results = list()\n",
    " n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    " # define evaluation procedure\n",
    " cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# define modeld\n",
    " model_nn = KerasRegressor(model = get_model) #(n_inputs, n_outputs, activation=\"relu\", init_mode='uniform'))\n",
    " # fit model\n",
    " grid = GridSearchCV(estimator=model_nn, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    " grid_result = grid.fit(X_train, y_train) # evaluate model on test set\n",
    " mae = model_nn.evaluate(X_test, y_test)\n",
    " # store result\n",
    " print('>%.3f' % mae)\n",
    " results.append(mae)\n",
    " return results\n",
    " \n",
    "# evaluate model\n",
    "results = evaluate_model(X, y)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(results), std(results)))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
