{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dres2\\AppData\\Local\\Temp\\ipykernel_7800\\4052692268.py:56: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def fullRead(pathToTable, sep, anthro = False):\n",
    "\n",
    "  df_renamed = pd.read_csv(pathToTable, sep = sep, encoding = \"latin_1\")\n",
    "\n",
    "\n",
    "  # reading and merging    \n",
    "  \n",
    "  if anthro == True:\n",
    "    df_anthro = pd.read_csv(\"data/chronicAnthropometricCardiovascularData.csv\", sep=\";\", decimal=\",\")\n",
    "    df_renamed = df_renamed.merge(df_anthro)\n",
    "\n",
    "    # separating by time moment and renaming\n",
    "\n",
    "    df_renamed[\"Weight\"] = \"\"\n",
    "    df_renamed[\"BMI\"] = \"\"\n",
    "    df_renamed[\"Fat\"] = \"\"\n",
    "    df_renamed[\"CVRI\"] = \"\"\n",
    "    df_renamed[\"Bpmin\"] = \"\"\n",
    "    df_renamed[\"Bpmax\"] = \"\"\n",
    "    df_renamed[\"Frec\"] = \"\"\n",
    "\n",
    "    for i in range(len(df_renamed)):\n",
    "\n",
    "        if df_renamed.loc[i][\"Time\"] == \"Initial\":\n",
    "            df_renamed.loc[i,\"Weight\"] = df_renamed.loc[i][\"Peso inicial\"]\n",
    "            df_renamed.loc[i,\"BMI\"] = df_renamed.loc[i][\"IMC Inicial\"]\n",
    "            df_renamed.loc[i,\"Fat\"] = df_renamed.loc[i][\"Grasa inicial\"]\n",
    "            df_renamed.loc[i,\"CVRI\"] = df_renamed.loc[i][\"IRCV inicial\"] \n",
    "            df_renamed.loc[i,\"Bpmin\"] = df_renamed.loc[i][\"Bpmin inicial\"] \n",
    "            df_renamed.loc[i,\"Bpmax\"] = df_renamed.loc[i][\"Bpmax inicial\"] \n",
    "            df_renamed.loc[i,\"Frec\"] = df_renamed.loc[i][\"Frec inicial\"] \n",
    "                \n",
    "        if df_renamed.loc[i][\"Time\"] == \"Final\":\n",
    "        \n",
    "            df_renamed.loc[i,\"Weight\"] = df_renamed.loc[i][\"Peso final\"]\n",
    "            df_renamed.loc[i,\"BMI\"] = df_renamed.loc[i][\"IMC Final\"]\n",
    "            df_renamed.loc[i,\"Fat\"] = df_renamed.loc[i][\"Grasa final\"]\n",
    "            df_renamed.loc[i,\"CVRI\"] = df_renamed.loc[i][\"IRCV Final\"] \n",
    "            df_renamed.loc[i,\"Bpmin\"] = df_renamed.loc[i][\"Bpmin final\"] \n",
    "            df_renamed.loc[i,\"Bpmax\"] = df_renamed.loc[i][\"Bpmax final\"] \n",
    "            df_renamed.loc[i,\"Frec\"] = df_renamed.loc[i][\"Frec final\"] \n",
    "        \n",
    "    df_renamed.drop(columns = [\"Peso inicial\", \"Peso final\", \"Delta Peso\", \"Talla\", \"IMC Inicial\", \"IMC Final\", \"Delta IMC\", \"Grasa inicial\", \"Grasa final\", \"Delta Grasa\", \"IRCV Final\", \"IRCV inicial\", \"Bpmin final\", \"Bpmin inicial\", \"Bpmax final\", \"Bpmax inicial\", \"Frec final\", \"Frec inicial\",], inplace=True )\n",
    "  \n",
    "  df_renamed.drop(columns = [\"Unnamed: 0\", \"grouping\"], inplace=True )\n",
    "  df_renamed.fillna(0, inplace=True)\n",
    "  return df_renamed\n",
    "\n",
    "def scaling(df_read):\n",
    "   \n",
    "   scaler = preprocessing.MinMaxScaler()\n",
    "   numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n",
    "   df_read[numCols] = scaler.fit_transform(df_read[numCols])\n",
    "   return df_read\n",
    "\n",
    "df = scaling(fullRead(\"data/plasmAnt_ord.csv\",  sep = \",\", anthro= True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    " \n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(df[[\"Sweetener\", \"Sex\", \"Time\"]])\n",
    "df[[\"Sweetener\", \"Sex\", \"Time\"]] = enc.transform(df[[\"Sweetener\", \"Sex\",  \"Time\"]])\n",
    "\n",
    "# Initial = 1, Final = 0\n",
    "\n",
    "X, y = df[df[\"Time\"] == 1].drop([\"numVol\", \"Time\"], axis=1), df[df[\"Time\"] == 0].drop(['Time','numVol', 'Sweetener', 'Time', 'Sex', 'Weight','BMI', 'Fat', 'CVRI', 'Bpmin', 'Bpmax', 'Frec'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_full, y_full = df[df[\"Time\"] == 1].drop([\"numVol\", \"Time\"], axis=1), df[df[\"Time\"] == 0].drop(['Time','numVol', 'Sweetener', 'Time'], axis = 1)\n",
    "X_fulltrain, X_fulltest, y_fulltrain, y_fulltest = train_test_split(X_full, y_full, test_size=0.3, random_state=42)\n",
    "\n",
    "#X_test.to_csv(\"X_met_test_urineAnt.csv\", index=False)\n",
    "#X_fulltest.to_csv(\"X_full_test_urineAnt.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB MET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "MAE: 0.113 (0.035)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score, GridSearchCV\n",
    "\n",
    "xgbReg = XGBRegressor()\n",
    "#xgbRegFit = xgbReg.fit(X_train, y_train)\n",
    "\n",
    "param_grid = {'max_depth'        : [None, 1, 3, 5, 10, 20],\n",
    "              'subsample'        : [0.5, 1],\n",
    "              'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "              'booster'          : ['gbtree']\n",
    "             }\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = xgbReg, param_grid = param_grid, cv= 10, n_jobs=-1,\n",
    "                           verbose=2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_grid = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "cv = RepeatedKFold(n_splits=20, n_repeats=10, random_state=1)\n",
    "n_scores = cross_val_score(best_grid, X_test, y_test,  scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "n_scores = np.absolute(n_scores)\n",
    "\n",
    "print('MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "MAE: 0.110 (0.023)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score, GridSearchCV\n",
    "\n",
    "xgbReg = XGBRegressor()\n",
    "#xgbRegFit = xgbReg.fit(X_train, y_train)\n",
    "\n",
    "param_grid = {'max_depth'        : [None, 1, 3, 5, 10, 20],\n",
    "              'subsample'        : [0.5, 1],\n",
    "              'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "              'booster'          : ['gbtree']\n",
    "             }\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = xgbReg, param_grid = param_grid, cv= 10, n_jobs=-1,\n",
    "                           verbose=2)\n",
    "\n",
    "grid_search.fit(X_fulltrain, y_fulltrain)\n",
    "best_grid = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "cv = RepeatedKFold(n_splits=20, n_repeats=10, random_state=1)\n",
    "n_scores = cross_val_score(best_grid, X_fulltest, y_fulltest,  scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "n_scores = np.absolute(n_scores)\n",
    "\n",
    "print('MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More complex MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.117 (0.013)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV, cross_val_score\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "epochs = [10, 50, 100]\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "\n",
    "def get_model(n_inputs, n_outputs):\n",
    "    model_nn = Sequential()\n",
    "    model_nn.add(Dense(64, input_shape=(X.shape[1],),activation=\"relu\"))\n",
    "    model_nn.add(Dropout(0.5))\n",
    "    model_nn.add(Dense(32, activation=\"relu\"))\n",
    "    model_nn.add(Dropout(0.5))\n",
    "    model_nn.add(Dense(32, activation = \"relu\"))\n",
    "    model_nn.add(Dropout(0.7))\n",
    "    model_nn.add(Dense(16, activation = \"relu\"))\n",
    "    model_nn.add(Dropout(0.9))\n",
    "    model_nn.add(Dense(y.shape[1], activation='linear'))\n",
    "    model_nn.compile(loss='mae', optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "    return model_nn\n",
    "\n",
    "def evaluate_model(X, y):\n",
    " results = list()\n",
    " n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    " # define evaluation procedure\n",
    " cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# define modeld\n",
    " model_nn = KerasRegressor(model = get_model(n_inputs, n_outputs), optimizer=tf.keras.optimizers.Adam(), verbose=0)\n",
    " # fit model\n",
    " grid = GridSearchCV(estimator=model_nn, param_grid=param_grid, n_jobs=-1, cv=3, verbose=0)\n",
    " grid_result = grid.fit(X_train, y_train) # evaluate model on test set\n",
    " # summarize results\n",
    " best_grid = grid_result.best_estimator_\n",
    "# define the evaluation procedure\n",
    " cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    " n_scores = cross_val_score(best_grid, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force the scores to be positive\n",
    " n_scores = np.absolute(n_scores)\n",
    " print('MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "\n",
    "evaluate_model(X, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
