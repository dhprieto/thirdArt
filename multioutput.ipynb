{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.18584070e-02  1.23505972e-01  1.43340856e-01  1.33333340e-01\n",
      "  1.98405921e-01  4.91071433e-01  1.83281332e-01  1.30718946e-02\n",
      "  2.32588693e-01  8.80952403e-02  2.19358325e-01  6.16016379e-03\n",
      "  9.61744636e-02 -1.47907524e-16  9.62223485e-02  3.74886915e-02\n",
      "  9.51158926e-02  1.44801974e-01  3.61673415e-01  4.88988422e-02\n",
      "  1.12354688e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# example of multioutput regression test problem\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# linear regression for multioutput regression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# create datasets\n",
    "X, y = df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis=1), df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis = 1)\n",
    "# define model\n",
    "model = LinearRegression()\n",
    "# fit model\n",
    "model.fit(X, y)\n",
    "# make a prediction\n",
    "newX = np.asarray([df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis=1).loc[3]]).astype(\"float32\")\n",
    "yhat = model.predict(newX)\n",
    "# summarize prediction\n",
    "print(yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03115044 0.06795674 0.1227991  0.13333333 0.13219471 0.30197368\n",
      " 0.08325533 0.03496732 0.22575558 0.07373016 0.10923885 0.01225188\n",
      " 0.0994207  0.         0.0996611  0.01245603 0.0361567  0.14628713\n",
      " 0.24851552 0.03269877 0.047137  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# k-nearest neighbors for multioutput regression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# create datasets\n",
    "X, y = df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis=1), df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis = 1)\n",
    "# define model\n",
    "model = KNeighborsRegressor()\n",
    "# fit model\n",
    "model.fit(X, y)\n",
    "# make a prediction\n",
    "newX = np.asarray([df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis=1).loc[3]]).astype(\"float32\")\n",
    "yhat = model.predict(newX)\n",
    "# summarize prediction\n",
    "print(yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03185841 0.12350598 0.14334086 0.13333333 0.19840592 0.49107143\n",
      " 0.18328133 0.0130719  0.2325887  0.08809524 0.21935833 0.00616016\n",
      " 0.09617446 0.         0.09622235 0.03748869 0.0951159  0.14480198\n",
      " 0.36167341 0.04889884 0.11235468]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristina García\\AppData\\Local\\Temp\\ipykernel_26020\\1175743209.py:56: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X, y = df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis=1), df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis = 1)\n",
    "\n",
    "# decision tree for multioutput regression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "df1 = scaling(fullRead(\"data/urineAnt_ord.csv\", sep = \",\"))\n",
    "\n",
    "# define model\n",
    "model = DecisionTreeRegressor()\n",
    "# fit model\n",
    "model.fit(X, y)\n",
    "# make a prediction\n",
    "newX = np.asarray([df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis=1).loc[3]]).astype(\"float32\")\n",
    "yhat = model.predict(newX)\n",
    "# summarize prediction\n",
    "print(yhat[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 51.519 (3.026)\n"
     ]
    }
   ],
   "source": [
    "# evaluate multioutput regression model with k-fold cross-validation\n",
    "from numpy import absolute\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "# create datasets\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
    "# define model\n",
    "model = DecisionTreeRegressor()\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force the scores to be positive\n",
    "n_scores = absolute(n_scores)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1.264\n",
      "MAE: 1.264 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# mlp for multi-output regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    " X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=3, random_state=2)\n",
    " return X, y\n",
    " \n",
    "# get the model\n",
    "def get_model(n_inputs, n_outputs):\n",
    " model = Sequential()\n",
    " model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    " model.add(Dense(n_outputs))\n",
    " model.compile(loss='mae', optimizer='adam')\n",
    " return model\n",
    " \n",
    "# evaluate a model using repeated k-fold cross-validation\n",
    "def evaluate_model(X, y):\n",
    " results = list()\n",
    " n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    " # define evaluation procedure\n",
    " cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    " # enumerate folds\n",
    " for train_ix, test_ix in cv.split(X):\n",
    "    # prepare data\n",
    "    X_train, X_test = X[train_ix], X[test_ix]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    # define model\n",
    " model = get_model(n_inputs, n_outputs)\n",
    " # fit model\n",
    " model.fit(X_train, y_train, verbose=0, epochs=500)\n",
    " # evaluate model on test set\n",
    " mae = model.evaluate(X_test, y_test, verbose=0)\n",
    " # store result\n",
    " print('>%.3f' % mae)\n",
    " results.append(mae)\n",
    " return results\n",
    " \n",
    "# load dataset\n",
    "X, y = get_dataset()\n",
    "# evaluate model\n",
    "results = evaluate_model(X, y)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristina García\\AppData\\Local\\Temp\\ipykernel_26020\\1175743209.py:56: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.006\n",
      "MAE: 0.006 (0.000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def fullRead(pathToTable, sep, anthro = False):\n",
    "\n",
    "  df_renamed = pd.read_csv(pathToTable, sep = sep, encoding = \"latin_1\")\n",
    "\n",
    "\n",
    "  # reading and merging    \n",
    "  \n",
    "  if anthro == True:\n",
    "    df_anthro = pd.read_csv(\"data/chronicAnthropometricCardiovascularData.csv\", sep=\";\", decimal=\",\")\n",
    "    df_renamed = df_renamed.merge(df_anthro)\n",
    "\n",
    "    # separating by time moment and renaming\n",
    "\n",
    "    df_renamed[\"Weight\"] = \"\"\n",
    "    df_renamed[\"BMI\"] = \"\"\n",
    "    df_renamed[\"Fat\"] = \"\"\n",
    "    df_renamed[\"CVRI\"] = \"\"\n",
    "    df_renamed[\"Bpmin\"] = \"\"\n",
    "    df_renamed[\"Bpmax\"] = \"\"\n",
    "    df_renamed[\"Frec\"] = \"\"\n",
    "\n",
    "    for i in range(len(df_renamed)):\n",
    "\n",
    "        if df_renamed.loc[i][\"Time\"] == \"Initial\":\n",
    "            df_renamed.loc[i,\"Weight\"] = df_renamed.loc[i][\"Peso inicial\"]\n",
    "            df_renamed.loc[i,\"BMI\"] = df_renamed.loc[i][\"IMC Inicial\"]\n",
    "            df_renamed.loc[i,\"Fat\"] = df_renamed.loc[i][\"Grasa inicial\"]\n",
    "            df_renamed.loc[i,\"CVRI\"] = df_renamed.loc[i][\"IRCV inicial\"] \n",
    "            df_renamed.loc[i,\"Bpmin\"] = df_renamed.loc[i][\"Bpmin inicial\"] \n",
    "            df_renamed.loc[i,\"Bpmax\"] = df_renamed.loc[i][\"Bpmax inicial\"] \n",
    "            df_renamed.loc[i,\"Frec\"] = df_renamed.loc[i][\"Frec inicial\"] \n",
    "                \n",
    "        if df_renamed.loc[i][\"Time\"] == \"Final\":\n",
    "        \n",
    "            df_renamed.loc[i,\"Weight\"] = df_renamed.loc[i][\"Peso final\"]\n",
    "            df_renamed.loc[i,\"BMI\"] = df_renamed.loc[i][\"IMC Final\"]\n",
    "            df_renamed.loc[i,\"Fat\"] = df_renamed.loc[i][\"Grasa final\"]\n",
    "            df_renamed.loc[i,\"CVRI\"] = df_renamed.loc[i][\"IRCV Final\"] \n",
    "            df_renamed.loc[i,\"Bpmin\"] = df_renamed.loc[i][\"Bpmin final\"] \n",
    "            df_renamed.loc[i,\"Bpmax\"] = df_renamed.loc[i][\"Bpmax final\"] \n",
    "            df_renamed.loc[i,\"Frec\"] = df_renamed.loc[i][\"Frec final\"] \n",
    "        \n",
    "    df_renamed.drop(columns = [\"Peso inicial\", \"Peso final\", \"Delta Peso\", \"Talla\", \"IMC Inicial\", \"IMC Final\", \"Delta IMC\", \"Grasa inicial\", \"Grasa final\", \"Delta Grasa\", \"IRCV Final\", \"IRCV inicial\", \"Bpmin final\", \"Bpmin inicial\", \"Bpmax final\", \"Bpmax inicial\", \"Frec final\", \"Frec inicial\",], inplace=True )\n",
    "  \n",
    "  df_renamed.drop(columns = [\"Unnamed: 0\", \"grouping\"], inplace=True )\n",
    "  df_renamed.fillna(0, inplace=True)\n",
    "  return df_renamed\n",
    "\n",
    "def scaling(df_read):\n",
    "   \n",
    "   scaler = preprocessing.MinMaxScaler()\n",
    "   numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n",
    "   df_read[numCols] = scaler.fit_transform(df_read[numCols])\n",
    "   return df_read\n",
    "\n",
    "df1 = scaling(fullRead(\"data/urineAnt_ord.csv\", sep = \",\"))\n",
    "\n",
    "# mlp for multi-output regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "#enc = OrdinalEncoder()\n",
    "#enc.fit(df1[[\"Sweetener\", \"Time\"]])\n",
    "#df1[[\"Sweetener\", \"Time\"]] = enc.transform(df1[[\"Sweetener\", \"Time\"]])\n",
    "\n",
    "X, y = df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis=1), df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# get the model\n",
    "def get_model(n_inputs, n_outputs):\n",
    " model = Sequential()\n",
    " model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    " model.add(Dense(n_outputs))\n",
    " model.compile(loss='mae', optimizer='adam')\n",
    " return model\n",
    "\n",
    "# evaluate a model using repeated k-fold cross-validation\n",
    "def evaluate_model(X, y, X_train, X_test, y_train, y_test):\n",
    " results = list()\n",
    " n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    " # define evaluation procedure\n",
    " cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    " # enumerate folds\n",
    " #for train_ix, test_ix in cv.split(X):\n",
    "  #  print (train_ix)\n",
    "    # prepare data\n",
    "    # X_train, X_test = X[train_ix], X[test_ix]\n",
    "    # y_train, y_test = y[train_ix], y[test_ix]\n",
    "    # define model\n",
    " model = get_model(n_inputs, n_outputs)\n",
    " # fit model\n",
    " model.fit(X_train, y_train, verbose=0, epochs=500)\n",
    " # evaluate model on test set\n",
    " mae = model.evaluate(X_test, y_test, verbose=0)\n",
    " # store result\n",
    " print('>%.3f' % mae)\n",
    " results.append(mae)\n",
    " return results \n",
    "\n",
    "# load dataset\n",
    "X , y = df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis=1), df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis = 1)\n",
    "# evaluate model\n",
    "results = evaluate_model(X, y, X_train, X_test, y_train, y_test)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(results), std(results)))\n",
    "\n",
    "#from numpy import asarray\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [0.03103105 0.12240787 0.14479874 0.13356082 0.19783299 0.48872373\n",
      " 0.18483038 0.00840865 0.23337819 0.05500548 0.21894526 0.01001675\n",
      " 0.09505448 0.00226916 0.09554845 0.00535768 0.09534689 0.14364983\n",
      " 0.18665953 0.03675731 0.10333917]\n"
     ]
    }
   ],
   "source": [
    "X, y = df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis=1), df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis = 1)\n",
    "\n",
    "def get_model(n_inputs, n_outputs):\n",
    " model = Sequential()\n",
    " model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    " model.add(Dense(n_outputs, kernel_initializer='he_uniform'))\n",
    " model.compile(loss='mae', optimizer='adam')\n",
    " return model\n",
    "\n",
    "model = get_model(X.shape[1], y.shape[1])\n",
    "model.fit(X, y, verbose=0, epochs=500)\n",
    "newX = np.asarray([df1.drop([\"numVol\", \"Sex\", \"Time\", \"Sweetener\"], axis=1).loc[3]]).astype(\"float32\")\n",
    "yhat = model.predict(newX)\n",
    "print('Predicted: %s' % yhat[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
