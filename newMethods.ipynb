{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dres2\\AppData\\Local\\Temp\\ipykernel_5800\\2971317607.py:58: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def fullRead(pathToTable, sep, anthro = False):\n",
    "\n",
    "  df_renamed = pd.read_csv(pathToTable, sep = sep, encoding = \"latin_1\")\n",
    "\n",
    "\n",
    "  # reading and merging    \n",
    "  \n",
    "  if anthro == True:\n",
    "    df_anthro = pd.read_csv(\"data/chronicAnthropometricCardiovascularData.csv\", sep=\";\", decimal=\",\")\n",
    "    df_renamed = df_renamed.merge(df_anthro)\n",
    "\n",
    "    # separating by time moment and renaming\n",
    "\n",
    "    df_renamed[\"Weight\"] = \"\"\n",
    "    df_renamed[\"BMI\"] = \"\"\n",
    "    df_renamed[\"Fat\"] = \"\"\n",
    "    df_renamed[\"CVRI\"] = \"\"\n",
    "    df_renamed[\"Bpmin\"] = \"\"\n",
    "    df_renamed[\"Bpmax\"] = \"\"\n",
    "    df_renamed[\"Frec\"] = \"\"\n",
    "\n",
    "    for i in range(len(df_renamed)):\n",
    "\n",
    "        if df_renamed.loc[i][\"Time\"] == \"Initial\":\n",
    "            df_renamed.loc[i,\"Weight\"] = df_renamed.loc[i][\"Peso inicial\"]\n",
    "            df_renamed.loc[i,\"BMI\"] = df_renamed.loc[i][\"IMC Inicial\"]\n",
    "            df_renamed.loc[i,\"Fat\"] = df_renamed.loc[i][\"Grasa inicial\"]\n",
    "            df_renamed.loc[i,\"CVRI\"] = df_renamed.loc[i][\"IRCV inicial\"] \n",
    "            df_renamed.loc[i,\"Bpmin\"] = df_renamed.loc[i][\"Bpmin inicial\"] \n",
    "            df_renamed.loc[i,\"Bpmax\"] = df_renamed.loc[i][\"Bpmax inicial\"] \n",
    "            df_renamed.loc[i,\"Frec\"] = df_renamed.loc[i][\"Frec inicial\"] \n",
    "                \n",
    "        if df_renamed.loc[i][\"Time\"] == \"Final\":\n",
    "        \n",
    "            df_renamed.loc[i,\"Weight\"] = df_renamed.loc[i][\"Peso final\"]\n",
    "            df_renamed.loc[i,\"BMI\"] = df_renamed.loc[i][\"IMC Final\"]\n",
    "            df_renamed.loc[i,\"Fat\"] = df_renamed.loc[i][\"Grasa final\"]\n",
    "            df_renamed.loc[i,\"CVRI\"] = df_renamed.loc[i][\"IRCV Final\"] \n",
    "            df_renamed.loc[i,\"Bpmin\"] = df_renamed.loc[i][\"Bpmin final\"] \n",
    "            df_renamed.loc[i,\"Bpmax\"] = df_renamed.loc[i][\"Bpmax final\"] \n",
    "            df_renamed.loc[i,\"Frec\"] = df_renamed.loc[i][\"Frec final\"] \n",
    "        \n",
    "    df_renamed.drop(columns = [\"Peso inicial\", \"Peso final\", \"Delta Peso\", \"Talla\", \"IMC Inicial\", \"IMC Final\", \"Delta IMC\", \"Grasa inicial\", \"Grasa final\", \"Delta Grasa\", \"IRCV Final\", \"IRCV inicial\", \"Bpmin final\", \"Bpmin inicial\", \"Bpmax final\", \"Bpmax inicial\", \"Frec final\", \"Frec inicial\",], inplace=True )\n",
    "  \n",
    "  df_renamed.drop(columns = [\"Unnamed: 0\", \"grouping\"], inplace=True )\n",
    "  df_renamed.fillna(0, inplace=True)\n",
    "  return df_renamed\n",
    "\n",
    "def scaling(df_read):\n",
    "   \n",
    "   scaler = preprocessing.MinMaxScaler()\n",
    "   numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n",
    "   df_read[numCols] = scaler.fit_transform(df_read[numCols])\n",
    "   return df_read\n",
    "\n",
    "df = scaling(fullRead(\"data/plasmAnt_ord.csv\",  sep = \",\", anthro= True))\n",
    "\n",
    "df = pd.get_dummies(df, columns = [\"Sweetener\", \"Sex\", \"Time\"], drop_first=False)\n",
    " \n",
    "X, y = df[df[\"Time_Initial\"] == 1].drop([\"numVol\", \"Time_Initial\", \"Time_Final\"], axis=1), df[df[\"Time_Final\"] == 1].drop([\n",
    "    'Sweetener_SA', 'Sweetener_ST','Sweetener_SU', 'Sex_MAN', 'Sex_WOMAN', 'Time_Final', 'Time_Initial','numVol', 'Weight','BMI', 'Fat', 'CVRI', 'Bpmin', 'Bpmax', 'Frec'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_full, y_full = df[df[\"Time_Initial\"] == 1].drop([\"numVol\", \"Time_Initial\", \"Time_Final\"], axis=1), df[df[\"Time_Final\"] == 1].drop(['numVol','Sweetener_SA', 'Sweetener_ST','Sweetener_SU','Time_Final', 'Time_Initial'], axis = 1)\n",
    "X_fulltrain, X_fulltest, y_fulltrain, y_fulltest = train_test_split(X_full, y_full, test_size=0.3, random_state=42)\n",
    "\n",
    "#X_test.to_csv(\"X_met_test_urineAnt.csv\", index=False)\n",
    "#X_fulltest.to_csv(\"X_full_test_urineAnt.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB MET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dres2\\Documents\\repositories\\thirdArt\\newMethods.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/newMethods.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m param_grid \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m        : [\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m20\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/newMethods.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39msubsample\u001b[39m\u001b[39m'\u001b[39m        : [\u001b[39m0.5\u001b[39m, \u001b[39m1\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/newMethods.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m    : [\u001b[39m0.001\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m0.1\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/newMethods.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mbooster\u001b[39m\u001b[39m'\u001b[39m          : [\u001b[39m'\u001b[39m\u001b[39mgbtree\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgblinear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdart\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/newMethods.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m              }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/newMethods.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator \u001b[39m=\u001b[39m xgbReg, param_grid \u001b[39m=\u001b[39m param_grid, cv\u001b[39m=\u001b[39m \u001b[39m10\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/newMethods.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                            verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/newMethods.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m grid_search\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/newMethods.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m best_grid \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/newMethods.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m cv \u001b[39m=\u001b[39m RepeatedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, n_repeats\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39mresult(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score, GridSearchCV\n",
    "\n",
    "xgbReg = XGBRegressor()\n",
    "#xgbRegFit = xgbReg.fit(X_train, y_train)\n",
    "\n",
    "param_grid = {'max_depth'        : [None, 1, 3, 5, 10, 20],\n",
    "              'subsample'        : [0.5, 1],\n",
    "              'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "              'booster'          : ['gbtree', 'gblinear', 'dart']\n",
    "             }\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = xgbReg, param_grid = param_grid, cv= 10, n_jobs=-1,\n",
    "                           verbose=2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_grid = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "cv = RepeatedKFold(n_splits=20, n_repeats=10, random_state=1)\n",
    "n_scores = cross_val_score(best_grid, X_test, y_test,  scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "n_scores = np.absolute(n_scores)\n",
    "\n",
    "print('MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n",
      "MAE: 0.059 (0.017)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score, GridSearchCV\n",
    "\n",
    "xgbReg = XGBRegressor()\n",
    "#xgbRegFit = xgbReg.fit(X_train, y_train)\n",
    "\n",
    "param_grid = {'max_depth'        : [None, 1, 3, 5, 10, 20],\n",
    "              'subsample'        : [0.5, 1],\n",
    "              'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "              'booster'          : ['gbtree', 'gblinear', 'dart']\n",
    "             }\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = xgbReg, param_grid = param_grid, cv= 10, n_jobs=-1,\n",
    "                           verbose=2)\n",
    "\n",
    "grid_search.fit(X_fulltrain, y_fulltrain)\n",
    "best_grid = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "cv = RepeatedKFold(n_splits=20, n_repeats=10, random_state=1)\n",
    "n_scores = cross_val_score(best_grid, X_fulltest, y_fulltest,  scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "n_scores = np.absolute(n_scores)\n",
    "\n",
    "print('MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More complex MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.117 (0.013)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV, cross_val_score\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "epochs = [10, 50, 100]\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "\n",
    "def get_model(n_inputs, n_outputs):\n",
    "    model_nn = Sequential()\n",
    "    model_nn.add(Dense(64, input_shape=(X.shape[1],),activation=\"relu\"))\n",
    "    model_nn.add(Dropout(0.5))\n",
    "    model_nn.add(Dense(32, activation=\"relu\"))\n",
    "    model_nn.add(Dropout(0.5))\n",
    "    model_nn.add(Dense(32, activation = \"relu\"))\n",
    "    model_nn.add(Dropout(0.7))\n",
    "    model_nn.add(Dense(16, activation = \"relu\"))\n",
    "    model_nn.add(Dropout(0.9))\n",
    "    model_nn.add(Dense(y.shape[1], activation='linear'))\n",
    "    model_nn.compile(loss='mae', optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "    return model_nn\n",
    "\n",
    "def evaluate_model(X, y):\n",
    " results = list()\n",
    " n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    " # define evaluation procedure\n",
    " cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# define modeld\n",
    " model_nn = KerasRegressor(model = get_model(n_inputs, n_outputs), optimizer=tf.keras.optimizers.Adam(), verbose=0)\n",
    " # fit model\n",
    " grid = GridSearchCV(estimator=model_nn, param_grid=param_grid, n_jobs=-1, cv=3, verbose=0)\n",
    " grid_result = grid.fit(X_train, y_train) # evaluate model on test set\n",
    " # summarize results\n",
    " best_grid = grid_result.best_estimator_\n",
    "# define the evaluation procedure\n",
    " cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    " n_scores = cross_val_score(best_grid, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force the scores to be positive\n",
    " n_scores = np.absolute(n_scores)\n",
    " print('MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "\n",
    "evaluate_model(X, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
