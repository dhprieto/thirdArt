{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading, cleaning, scaling, enconding and spliting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import \n",
    "import re \n",
    "\n",
    "def fullRead(pathToTable, sep, anthro = False):\n",
    "\n",
    "  df_renamed = pd.read_csv(pathToTable, sep = sep, encoding = \"latin_1\")\n",
    "  \n",
    "  df_name = re.sub(\"_ord.csv\",\"\",(re.sub(\"data/\", \"\" ,pathToTable)))\n",
    "  # reading and merging    \n",
    "  \n",
    "  if anthro == True:\n",
    "    df_anthro = pd.read_csv(\"data/chronicAnthropometricCardiovascularData.csv\", sep=\";\", decimal=\",\")\n",
    "    df_renamed = df_renamed.merge(df_anthro)\n",
    "\n",
    "    # separating by time moment and renaming\n",
    "\n",
    "    df_renamed[\"Weight\"] = \"\"\n",
    "    df_renamed[\"BMI\"] = \"\"\n",
    "    df_renamed[\"Fat\"] = \"\"\n",
    "    df_renamed[\"CVRI\"] = \"\"\n",
    "    df_renamed[\"Bpmin\"] = \"\"\n",
    "    df_renamed[\"Bpmax\"] = \"\"\n",
    "    df_renamed[\"Frec\"] = \"\"\n",
    "\n",
    "    for i in range(len(df_renamed)):\n",
    "\n",
    "        if df_renamed.loc[i][\"Time\"] == \"Initial\":\n",
    "            df_renamed.loc[i,\"Weight\"] = df_renamed.loc[i][\"Peso inicial\"]\n",
    "            df_renamed.loc[i,\"BMI\"] = df_renamed.loc[i][\"IMC Inicial\"]\n",
    "            df_renamed.loc[i,\"Fat\"] = df_renamed.loc[i][\"Grasa inicial\"]\n",
    "            df_renamed.loc[i,\"CVRI\"] = df_renamed.loc[i][\"IRCV inicial\"] \n",
    "            df_renamed.loc[i,\"Bpmin\"] = df_renamed.loc[i][\"Bpmin inicial\"] \n",
    "            df_renamed.loc[i,\"Bpmax\"] = df_renamed.loc[i][\"Bpmax inicial\"] \n",
    "            df_renamed.loc[i,\"Frec\"] = df_renamed.loc[i][\"Frec inicial\"] \n",
    "                \n",
    "        if df_renamed.loc[i][\"Time\"] == \"Final\":\n",
    "        \n",
    "            df_renamed.loc[i,\"Weight\"] = df_renamed.loc[i][\"Peso final\"]\n",
    "            df_renamed.loc[i,\"BMI\"] = df_renamed.loc[i][\"IMC Final\"]\n",
    "            df_renamed.loc[i,\"Fat\"] = df_renamed.loc[i][\"Grasa final\"]\n",
    "            df_renamed.loc[i,\"CVRI\"] = df_renamed.loc[i][\"IRCV Final\"] \n",
    "            df_renamed.loc[i,\"Bpmin\"] = df_renamed.loc[i][\"Bpmin final\"] \n",
    "            df_renamed.loc[i,\"Bpmax\"] = df_renamed.loc[i][\"Bpmax final\"] \n",
    "            df_renamed.loc[i,\"Frec\"] = df_renamed.loc[i][\"Frec final\"] \n",
    "        \n",
    "    df_renamed.drop(columns = [\"Peso inicial\", \"Peso final\", \"Delta Peso\", \"Talla\", \"IMC Inicial\", \"IMC Final\", \"Delta IMC\", \"Grasa inicial\", \"Grasa final\", \"Delta Grasa\", \"IRCV Final\", \"IRCV inicial\", \"Bpmin final\", \"Bpmin inicial\", \"Bpmax final\", \"Bpmax inicial\", \"Frec final\", \"Frec inicial\",], inplace=True )\n",
    "  \n",
    "  df_renamed.drop(columns = [\"Unnamed: 0\", \"grouping\"], inplace=True )\n",
    "  df_renamed.fillna(0, inplace=True)\n",
    "  return (df_renamed, df_name)\n",
    "\n",
    "def scaling(df_read):\n",
    "   \n",
    "   scaler = preprocessing.MinMaxScaler()\n",
    "   numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n",
    "   df_read[numCols] = scaler.fit_transform(df_read[numCols])\n",
    "   return df_read\n",
    "\n",
    "def encodingSplitting(df):\n",
    "  df = pd.get_dummies(df, columns = [\"Sweetener\", \"Sex\", \"Time\"], drop_first=False)\n",
    "  X_met, y_met = df[df[\"Time_Initial\"] == 1].drop([\"numVol\", \"Time_Initial\", \"Time_Final\"], axis=1), df[df[\"Time_Final\"] == 1].drop(['Sweetener_SA', 'Sweetener_ST','Sweetener_SU', 'Sex_MAN', 'Sex_WOMAN', 'Time_Final', 'Time_Initial','numVol', 'Weight','BMI', 'Fat', 'CVRI', 'Bpmin', 'Bpmax', 'Frec'], axis = 1)\n",
    "  X_metTrain, X_metTest, y_metTrain, y_metTest = train_test_split(X_met, y_met, test_size=0.2, random_state=42)\n",
    "\n",
    "  X_full, y_full = df[df[\"Time_Initial\"] == 1].drop([\"numVol\", \"Time_Initial\", \"Time_Final\"], axis=1), df[df[\"Time_Final\"] == 1].drop(['numVol','Sweetener_SA', 'Sweetener_ST','Sweetener_SU','Time_Final', 'Time_Initial'], axis = 1)\n",
    "  X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = train_test_split(X_full, y_full, test_size=0.3, random_state=42)\n",
    "\n",
    "  return(X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest)\n",
    "\n",
    "\n",
    "#df_PF = pd.get_dummies(scaling(fullRead(\"data/plasmFlav_ord.csv\",  sep = \",\", anthro= True)), columns = [\"Sweetener\", \"Sex\", \"Time\"], drop_first=False)\n",
    "#df_PA = scaling(fullRead(\"data/plasmAnt_ord.csv\",  sep = \",\", anthro= True))\n",
    "#df_UF = scaling(fullRead(\"data/urineFlav_ord.csv\",  sep = \",\", anthro= True))\n",
    "#df_UA = scaling(fullRead(\"data/urineAnt_ord.csv\",  sep = \",\", anthro= True))\n",
    "#X_test.to_csv(\"X_met_test_urineAnt.csv\", index=False)\n",
    "#X_fulltest.to_csv(\"X_full_test_urineAnt.csv\",index=False)\n",
    "\n",
    "def XGBReg (df, df_name, met):\n",
    "\n",
    "    X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = encodingSplitting(df)\n",
    "\n",
    "    if (met):\n",
    "        \n",
    "        xgbReg = XGBRegressor()\n",
    "\n",
    "        param_grid = {'max_depth'        : [None, 1, 3, 5, 10, 20],\n",
    "                    'subsample'        : [0.5, 1],\n",
    "                    'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "                    'booster'          : ['gbtree', 'gblinear', 'dart']\n",
    "                    }\n",
    "\n",
    "\n",
    "        grid_search = GridSearchCV(estimator = xgbReg, param_grid = param_grid, cv= 3, n_jobs=-1,\n",
    "                                verbose=2)\n",
    "\n",
    "        grid_search.fit(X_metTrain, y_metTrain)\n",
    "        best_grid = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "        cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "        n_scores = cross_val_score(best_grid, X_metTest, y_metTest,  scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "        n_scores = np.absolute(n_scores)\n",
    "\n",
    "        print(\"Only metabolic model \" + df_name +' MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "        MAE = (np.mean(n_scores), np.std(n_scores))\n",
    "        return(grid_search, MAE)\n",
    "    \n",
    "    else:\n",
    "        xgbReg = XGBRegressor()\n",
    "\n",
    "        param_grid = {'max_depth'        : [None, 1, 3, 5, 10, 20],\n",
    "                    'subsample'        : [0.5, 1],\n",
    "                    'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "                    'booster'          : ['gbtree', 'gblinear', 'dart']\n",
    "                    }\n",
    "\n",
    "\n",
    "        grid_search = GridSearchCV(estimator = xgbReg, param_grid = param_grid, cv= 3, n_jobs=-1,\n",
    "                                verbose=2)\n",
    "\n",
    "        grid_search.fit(X_fullTrain, y_fullTrain)\n",
    "        best_grid = grid_search.best_estimator_\n",
    "\n",
    "        cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "        n_scores = cross_val_score(best_grid, X_fullTest, y_fullTest,  scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "        n_scores = np.absolute(n_scores)\n",
    "\n",
    "        print(\"Full model \"+ df_name + ' MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "        MAE = (np.mean(n_scores), np.std(n_scores))\n",
    "        return(grid_search, MAE)        \n",
    "    \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# import pickle\n",
    "\n",
    "# define model\n",
    "\n",
    "def randomForestReg(df, df_name, met = True):\n",
    "\n",
    "    param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "    \n",
    "    if (met):\n",
    "        \n",
    "        X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = encodingSplitting(df)\n",
    "\n",
    "        model = RandomForestRegressor()\n",
    "\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "        grid_search.fit(X_metTrain, y_metTrain)\n",
    "        best_grid = grid_search.best_estimator_\n",
    "        # define the evaluation procedure\n",
    "        cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "        # evaluate the model and collect the scores\n",
    "        n_scores = cross_val_score(best_grid, X_metTest, y_metTest, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "        # force the scores to be positive\n",
    "        n_scores = np.absolute(n_scores)\n",
    "        # summarize performance\n",
    "\n",
    "        #filename = 'rf_met_plasmAnt.pkl'\n",
    "        #with open(filename, 'wb') as file:\n",
    "        #    pickle.dump(grid_search.best_estimator_, file)\n",
    "\n",
    "        print('Only Metabolic model ' + df_name + ': MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "        MAE = (np.mean(n_scores), np.std(n_scores))\n",
    "        return(grid_search, MAE)\n",
    "\n",
    "    else:\n",
    "            \n",
    "        X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = encodingSplitting(df)\n",
    "\n",
    "        model = RandomForestRegressor()\n",
    "\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = param_grid, \n",
    "                        cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "        grid_search.fit(X_fullTrain, y_fullTrain)\n",
    "        best_grid = grid_search.best_estimator_\n",
    "        # define the evaluation procedure\n",
    "        cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "        # evaluate the model and collect the scores\n",
    "        n_scores = cross_val_score(best_grid, X_fullTest, y_fullTest, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "        # force the scores to be positive\n",
    "        n_scores = np.absolute(n_scores)\n",
    "        # summarize performance\n",
    "\n",
    "        #filename = 'rf_met_plasmAnt.pkl'\n",
    "        #with open(filename, 'wb') as file:\n",
    "        #    pickle.dump(grid_search.best_estimator_, file)\n",
    "\n",
    "        print('Full model ' + df_name + ': MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "        MAE = (np.mean(n_scores), np.std(n_scores))\n",
    "        return(grid_search, MAE)\n",
    "\n",
    "# mlp for multi-output regression\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold, GridSearchCV\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "# fix random seed for reproducibility\n",
    "\n",
    "def MLPReg (df, df_name, met):\n",
    "    \n",
    "    if (met):\n",
    "        seed = 7\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "        X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = encodingSplitting(df)\n",
    "\n",
    "\n",
    "        epochs = [10, 50, 100]\n",
    "        batch_size = [10, 20, 40, 60, 80, 100]\n",
    "\n",
    "        param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "        # get the model\n",
    "        def get_model(n_inputs, n_outputs):\n",
    "            model_nn = Sequential()\n",
    "            model_nn.add(Dense(64, input_shape=(n_inputs,),activation=\"relu\"))\n",
    "            model_nn.add(Dropout(0.5))\n",
    "            model_nn.add(Dense(32, activation=\"relu\"))\n",
    "            model_nn.add(Dropout(0.5))\n",
    "            model_nn.add(Dense(n_outputs, activation='linear'))\n",
    "            model_nn.compile(loss='mae', optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "            return model_nn\n",
    "        \n",
    "        # evaluate a model using repeated k-fold cross-validation\n",
    "        def evaluate_model(X, y):\n",
    "            results = list()\n",
    "            n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "            # define evaluation procedure\n",
    "            cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            # define modeld\n",
    "            model_nn = KerasRegressor(model = get_model(n_inputs, n_outputs), optimizer=tf.keras.optimizers.Adam(), verbose=0)\n",
    "            # fit model\n",
    "            grid = GridSearchCV(estimator=model_nn, param_grid=param_grid, n_jobs=-1, cv=3, verbose=0)\n",
    "            grid_result = grid.fit(X_train, y_train) # evaluate model on test set\n",
    "            # summarize results\n",
    "            best_grid = grid_result.best_estimator_\n",
    "            # define the evaluation procedure\n",
    "            cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "            # evaluate the model and collect the scores\n",
    "            n_scores = cross_val_score(best_grid, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "            # force the scores to be positive\n",
    "            n_scores = np.absolute(n_scores)\n",
    "\n",
    "            # store the model\n",
    "            # filename = 'mlp_met_plasmAnt.pkl'\n",
    "            # with open(filename, 'wb') as file:\n",
    "            #    pickle.dump(grid_result.best_estimator_, file)\n",
    "\n",
    "            # summarize performance\n",
    "            print('Only Metabolic model ' + df_name +'MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "            MAE = (np.mean(n_scores), np.std(n_scores))\n",
    "            return(best_grid, MAE)\n",
    "            # evaluate model\n",
    "            \n",
    "        modelMLP, MAE = evaluate_model(X_met, y_met)\n",
    "    \n",
    "    else:\n",
    "        seed = 7\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "        X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = encodingSplitting(df)\n",
    "\n",
    "\n",
    "        epochs = [10, 50, 100]\n",
    "        batch_size = [10, 20, 40, 60, 80, 100]\n",
    "\n",
    "        param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "        # get the model\n",
    "        def get_model(n_inputs, n_outputs):\n",
    "            model_nn = Sequential()\n",
    "            model_nn.add(Dense(64, input_shape=(n_inputs,),activation=\"relu\"))\n",
    "            model_nn.add(Dropout(0.5))\n",
    "            model_nn.add(Dense(32, activation=\"relu\"))\n",
    "            model_nn.add(Dropout(0.5))\n",
    "            model_nn.add(Dense(n_outputs, activation='linear'))\n",
    "            model_nn.compile(loss='mae', optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "            return model_nn\n",
    "        \n",
    "        # evaluate a model using repeated k-fold cross-validation\n",
    "        def evaluate_model(X, y):\n",
    "            results = list()\n",
    "            n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "            # define evaluation procedure\n",
    "            cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            # define modeld\n",
    "            model_nn = KerasRegressor(model = get_model(n_inputs, n_outputs), optimizer=tf.keras.optimizers.Adam(), verbose=0)\n",
    "            # fit model\n",
    "            grid = GridSearchCV(estimator=model_nn, param_grid=param_grid, n_jobs=-1, cv=3, verbose=0)\n",
    "            grid_result = grid.fit(X_train, y_train) # evaluate model on test set\n",
    "            # summarize results\n",
    "            best_grid = grid_result.best_estimator_\n",
    "            # define the evaluation procedure\n",
    "            cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "            # evaluate the model and collect the scores\n",
    "            n_scores = cross_val_score(best_grid, X_test, y_test, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "            # force the scores to be positive\n",
    "            n_scores = np.absolute(n_scores)\n",
    "\n",
    "            # store the model\n",
    "            # filename = 'mlp_met_plasmAnt.pkl'\n",
    "            # with open(filename, 'wb') as file:\n",
    "            #    pickle.dump(grid_result.best_estimator_, file)\n",
    "\n",
    "            # summarize performance\n",
    "            print('Full model ' + df_name + 'MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "            MAE = (np.mean(n_scores), np.std(n_scores))\n",
    "            return(best_grid, MAE)\n",
    "            # evaluate model\n",
    "            \n",
    "        modelMLP, MAE = evaluate_model(X_full, y_full)    \n",
    "    return (modelMLP, MAE)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dres2\\AppData\\Local\\Temp\\ipykernel_16164\\2194238368.py:58: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Only Metabolic model plasmFlav: MAE: 0.053 (0.020)\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dres2\\AppData\\Local\\Temp\\ipykernel_16164\\2194238368.py:58: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model plasmFlav: MAE: 0.107 (0.010)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dres2\\AppData\\Local\\Temp\\ipykernel_16164\\2194238368.py:58: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Only Metabolic model plasmAnt: MAE: 0.103 (0.017)\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dres2\\AppData\\Local\\Temp\\ipykernel_16164\\2194238368.py:58: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model plasmAnt: MAE: 0.123 (0.011)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dres2\\AppData\\Local\\Temp\\ipykernel_16164\\2194238368.py:58: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Only Metabolic model urineFlav: MAE: 0.058 (0.019)\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dres2\\AppData\\Local\\Temp\\ipykernel_16164\\2194238368.py:58: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model urineFlav: MAE: 0.092 (0.012)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dres2\\AppData\\Local\\Temp\\ipykernel_16164\\2194238368.py:58: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Only Metabolic model urineAnt: MAE: 0.076 (0.014)\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dres2\\AppData\\Local\\Temp\\ipykernel_16164\\2194238368.py:58: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model urineAnt: MAE: 0.095 (0.008)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dres2\\AppData\\Local\\Temp\\ipykernel_16164\\2194238368.py:58: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only Metabolic model plasmFlavMAE: 0.053 (0.021)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dres2\\AppData\\Local\\Temp\\ipykernel_16164\\2194238368.py:58: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  numCols = df_read.select_dtypes(include=np.number).drop(\"numVol\",1).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model plasmFlavMAE: 0.091 (0.012)\n",
      "Only Metabolic model plasmAntMAE: 0.096 (0.019)\n",
      "Full model plasmAntMAE: 0.107 (0.017)\n",
      "Only Metabolic model urineFlavMAE: 0.052 (0.021)\n",
      "Full model urineFlavMAE: 0.078 (0.013)\n",
      "Only Metabolic model urineAntMAE: 0.071 (0.019)\n",
      "Full model urineAntMAE: 0.086 (0.013)\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Only metabolic model plasmFlav MAE: 0.066 (0.020)\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Full model plasmFlav MAE: 0.104 (0.009)\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Only metabolic model plasmAnt MAE: 0.109 (0.018)\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Full model plasmAnt MAE: 0.121 (0.015)\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Only metabolic model urineFlav MAE: 0.071 (0.026)\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Full model urineFlav MAE: 0.078 (0.015)\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Only metabolic model urineAnt MAE: 0.096 (0.059)\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Full model urineAnt MAE: 0.078 (0.010)\n"
     ]
    }
   ],
   "source": [
    "paths = [\"plasmFlav_ord.csv\", \"plasmAnt_ord.csv\", \"urineFlav_ord.csv\", \"urineAnt_ord.csv\"]\n",
    "paths = [\"data/\" + s for s in paths]\n",
    "\n",
    "resultsModelsRF = {}\n",
    "resultsScoresRF = {}\n",
    "\n",
    "for path in paths:\n",
    "    df, df_name = fullRead(path, sep = \",\", anthro = True)\n",
    "    resultsModelsRF[\"modelRFMet{0}\".format(df_name)], resultsScoresRF[\"modelRFMet{0}\".format(df_name)] = randomForestReg(scaling(df), df_name, met = True)\n",
    "    resultsModelsRF[\"modelRFFull{0}\".format(df_name)], resultsScoresRF[\"modelRFFull{0}\".format(df_name)] = randomForestReg(scaling(df), df_name, met = False)\n",
    "\n",
    "#modelRFMet = randomForestReg(scaling(fullRead(\"data/plasmFlav_ord.csv\",  sep = \",\", anthro= True)[0]), met = True)\n",
    "#modelRFFull = randomForestReg(scaling(fullRead(\"data/plasmFlav_ord.csv\",  sep = \",\", anthro= True)), met = False)\n",
    "\n",
    "resultsModelsMLP = {}\n",
    "resultsScoresMLP = {}\n",
    "\n",
    "for path in paths:\n",
    "    df, df_name = fullRead(path, sep = \",\", anthro = True)\n",
    "    resultsModelsMLP[\"modelMLPMet{0}\".format(df_name)], resultsScoresMLP[\"modelMLPMet{0}\".format(df_name)] = MLPReg(scaling(df), df_name, met = True)\n",
    "    resultsModelsMLP[\"modelMLPFull{0}\".format(df_name)], resultsScoresMLP[\"modelMLPFull{0}\".format(df_name)] = MLPReg(scaling(df), df_name, met = False)\n",
    "\n",
    "resultsModelsXGB = {}\n",
    "resultsScoresXGB = {}\n",
    "\n",
    "for path in paths:\n",
    "    df, df_name = fullRead(path, sep = \",\", anthro = True)\n",
    "    resultsModelsXGB[\"modelXGBMet{0}\".format(df_name)], resultsScoresXGB[\"modelXGBMet{0}\".format(df_name)] = XGBReg(scaling(df), df_name, met = True)\n",
    "    resultsModelsXGB[\"modelXGBFull{0}\".format(df_name)], resultsScoresXGB[\"modelXGBFull{0}\".format(df_name)] = XGBReg(scaling(df), df_name, met = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save models and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary saved successfully to file\n",
      "dictionary saved successfully to file\n",
      "dictionary saved successfully to file\n",
      "dictionary saved successfully to file\n",
      "dictionary saved successfully to file\n",
      "dictionary saved successfully to file\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('resultsScoresXGB.pkl', 'wb') as fp:\n",
    "    pickle.dump(resultsScoresXGB, fp)\n",
    "    print('dictionary saved successfully to file')\n",
    "\n",
    "with open('resultsModelsXGB.pkl', 'wb') as fp:\n",
    "    pickle.dump(resultsModelsXGB, fp)\n",
    "    print('dictionary saved successfully to file')\n",
    "\n",
    "with open('resultsModelsRF.pkl', 'wb') as fp:\n",
    "    pickle.dump(resultsModelsRF, fp)\n",
    "    print('dictionary saved successfully to file')\n",
    "\n",
    "with open('resultsScoresRF.pkl', 'wb') as fp:\n",
    "    pickle.dump(resultsScoresRF, fp)\n",
    "    print('dictionary saved successfully to file')\n",
    "\n",
    "with open('resultsModelsMLP.pkl', 'wb') as fp:\n",
    "    pickle.dump(resultsModelsMLP, fp)\n",
    "    print('dictionary saved successfully to file')\n",
    "\n",
    "with open('resultsScoresMLP.pkl', 'wb') as fp:\n",
    "    pickle.dump(resultsScoresMLP, fp)\n",
    "    print('dictionary saved successfully to file')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'modelRFMetplasmFlav': (0.0532847365867248, 0.01977346767254395), 'modelRFFullplasmFlav': (0.10696776551543523, 0.009848618987364182), 'modelRFMetplasmAnt': (0.10290259653225461, 0.016654608318190822), 'modelRFFullplasmAnt': (0.12322590948062656, 0.011219636067256301), 'modelRFMeturineFlav': (0.05782773891531134, 0.018523719944373546), 'modelRFFullurineFlav': (0.09180663884536393, 0.01192785767544677), 'modelRFMeturineAnt': (0.07589460272747764, 0.013883260488188897), 'modelRFFullurineAnt': (0.09526396651665503, 0.00828795141972093)}\n",
      "{'modelXGBMetplasmFlav': (0.06566482327975234, 0.020082282056815344), 'modelXGBFullplasmFlav': (0.10356092083391417, 0.00888166784887823), 'modelXGBMetplasmAnt': (0.10865072869562561, 0.018262876868377527), 'modelXGBFullplasmAnt': (0.12116975738171971, 0.01455740739431039), 'modelXGBMeturineFlav': (0.07141783691086166, 0.025876908715745373), 'modelXGBFullurineFlav': (0.07846439120335927, 0.015187261180223337), 'modelXGBMeturineAnt': (0.09574489401411923, 0.05934625827657657), 'modelXGBFullurineAnt': (0.0778253075732373, 0.010167032490283107)}\n",
      "{'modelMLPMetplasmFlav': (0.05330635971787647, 0.021082412547452776), 'modelMLPFullplasmFlav': (0.09135256043613242, 0.012082148335000679), 'modelMLPMetplasmAnt': (0.09560999624066933, 0.01930066709426625), 'modelMLPFullplasmAnt': (0.10658035083384859, 0.016766312486281864), 'modelMLPMeturineFlav': (0.05164901858214523, 0.020806790640723646), 'modelMLPFullurineFlav': (0.07785916471398789, 0.012520268717827838), 'modelMLPMeturineAnt': (0.07103158914760105, 0.01931936371040373), 'modelMLPFullurineAnt': (0.08627641295758814, 0.013193125125387214)}\n",
      "{'modelRFMetplasmFlav': GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
      "             param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110],\n",
      "                         'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],\n",
      "                         'min_samples_split': [8, 10, 12],\n",
      "                         'n_estimators': [100, 200, 300, 1000]},\n",
      "             verbose=2), 'modelRFFullplasmFlav': GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
      "             param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110],\n",
      "                         'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],\n",
      "                         'min_samples_split': [8, 10, 12],\n",
      "                         'n_estimators': [100, 200, 300, 1000]},\n",
      "             verbose=2), 'modelRFMetplasmAnt': GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
      "             param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110],\n",
      "                         'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],\n",
      "                         'min_samples_split': [8, 10, 12],\n",
      "                         'n_estimators': [100, 200, 300, 1000]},\n",
      "             verbose=2), 'modelRFFullplasmAnt': GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
      "             param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110],\n",
      "                         'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],\n",
      "                         'min_samples_split': [8, 10, 12],\n",
      "                         'n_estimators': [100, 200, 300, 1000]},\n",
      "             verbose=2), 'modelRFMeturineFlav': GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
      "             param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110],\n",
      "                         'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],\n",
      "                         'min_samples_split': [8, 10, 12],\n",
      "                         'n_estimators': [100, 200, 300, 1000]},\n",
      "             verbose=2), 'modelRFFullurineFlav': GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
      "             param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110],\n",
      "                         'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],\n",
      "                         'min_samples_split': [8, 10, 12],\n",
      "                         'n_estimators': [100, 200, 300, 1000]},\n",
      "             verbose=2), 'modelRFMeturineAnt': GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
      "             param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110],\n",
      "                         'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],\n",
      "                         'min_samples_split': [8, 10, 12],\n",
      "                         'n_estimators': [100, 200, 300, 1000]},\n",
      "             verbose=2), 'modelRFFullurineAnt': GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
      "             param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110],\n",
      "                         'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],\n",
      "                         'min_samples_split': [8, 10, 12],\n",
      "                         'n_estimators': [100, 200, 300, 1000]},\n",
      "             verbose=2)}\n",
      "{'modelXGBMetplasmFlav': GridSearchCV(cv=3,\n",
      "             estimator=XGBRegressor(base_score=None, booster=None,\n",
      "                                    callbacks=None, colsample_bylevel=None,\n",
      "                                    colsample_bynode=None,\n",
      "                                    colsample_bytree=None, device=None,\n",
      "                                    early_stopping_rounds=None,\n",
      "                                    enable_categorical=False, eval_metric=None,\n",
      "                                    feature_types=None, gamma=None,\n",
      "                                    grow_policy=None, importance_type=None,\n",
      "                                    interaction_constraints=None,\n",
      "                                    learning_rate=None, m...\n",
      "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
      "                                    max_depth=None, max_leaves=None,\n",
      "                                    min_child_weight=None, missing=nan,\n",
      "                                    monotone_constraints=None,\n",
      "                                    multi_strategy=None, n_estimators=None,\n",
      "                                    n_jobs=None, num_parallel_tree=None,\n",
      "                                    random_state=None, ...),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'booster': ['gbtree', 'gblinear', 'dart'],\n",
      "                         'learning_rate': [0.001, 0.01, 0.1],\n",
      "                         'max_depth': [None, 1, 3, 5, 10, 20],\n",
      "                         'subsample': [0.5, 1]},\n",
      "             verbose=2), 'modelXGBFullplasmFlav': GridSearchCV(cv=3,\n",
      "             estimator=XGBRegressor(base_score=None, booster=None,\n",
      "                                    callbacks=None, colsample_bylevel=None,\n",
      "                                    colsample_bynode=None,\n",
      "                                    colsample_bytree=None, device=None,\n",
      "                                    early_stopping_rounds=None,\n",
      "                                    enable_categorical=False, eval_metric=None,\n",
      "                                    feature_types=None, gamma=None,\n",
      "                                    grow_policy=None, importance_type=None,\n",
      "                                    interaction_constraints=None,\n",
      "                                    learning_rate=None, m...\n",
      "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
      "                                    max_depth=None, max_leaves=None,\n",
      "                                    min_child_weight=None, missing=nan,\n",
      "                                    monotone_constraints=None,\n",
      "                                    multi_strategy=None, n_estimators=None,\n",
      "                                    n_jobs=None, num_parallel_tree=None,\n",
      "                                    random_state=None, ...),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'booster': ['gbtree', 'gblinear', 'dart'],\n",
      "                         'learning_rate': [0.001, 0.01, 0.1],\n",
      "                         'max_depth': [None, 1, 3, 5, 10, 20],\n",
      "                         'subsample': [0.5, 1]},\n",
      "             verbose=2), 'modelXGBMetplasmAnt': GridSearchCV(cv=3,\n",
      "             estimator=XGBRegressor(base_score=None, booster=None,\n",
      "                                    callbacks=None, colsample_bylevel=None,\n",
      "                                    colsample_bynode=None,\n",
      "                                    colsample_bytree=None, device=None,\n",
      "                                    early_stopping_rounds=None,\n",
      "                                    enable_categorical=False, eval_metric=None,\n",
      "                                    feature_types=None, gamma=None,\n",
      "                                    grow_policy=None, importance_type=None,\n",
      "                                    interaction_constraints=None,\n",
      "                                    learning_rate=None, m...\n",
      "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
      "                                    max_depth=None, max_leaves=None,\n",
      "                                    min_child_weight=None, missing=nan,\n",
      "                                    monotone_constraints=None,\n",
      "                                    multi_strategy=None, n_estimators=None,\n",
      "                                    n_jobs=None, num_parallel_tree=None,\n",
      "                                    random_state=None, ...),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'booster': ['gbtree', 'gblinear', 'dart'],\n",
      "                         'learning_rate': [0.001, 0.01, 0.1],\n",
      "                         'max_depth': [None, 1, 3, 5, 10, 20],\n",
      "                         'subsample': [0.5, 1]},\n",
      "             verbose=2), 'modelXGBFullplasmAnt': GridSearchCV(cv=3,\n",
      "             estimator=XGBRegressor(base_score=None, booster=None,\n",
      "                                    callbacks=None, colsample_bylevel=None,\n",
      "                                    colsample_bynode=None,\n",
      "                                    colsample_bytree=None, device=None,\n",
      "                                    early_stopping_rounds=None,\n",
      "                                    enable_categorical=False, eval_metric=None,\n",
      "                                    feature_types=None, gamma=None,\n",
      "                                    grow_policy=None, importance_type=None,\n",
      "                                    interaction_constraints=None,\n",
      "                                    learning_rate=None, m...\n",
      "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
      "                                    max_depth=None, max_leaves=None,\n",
      "                                    min_child_weight=None, missing=nan,\n",
      "                                    monotone_constraints=None,\n",
      "                                    multi_strategy=None, n_estimators=None,\n",
      "                                    n_jobs=None, num_parallel_tree=None,\n",
      "                                    random_state=None, ...),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'booster': ['gbtree', 'gblinear', 'dart'],\n",
      "                         'learning_rate': [0.001, 0.01, 0.1],\n",
      "                         'max_depth': [None, 1, 3, 5, 10, 20],\n",
      "                         'subsample': [0.5, 1]},\n",
      "             verbose=2), 'modelXGBMeturineFlav': GridSearchCV(cv=3,\n",
      "             estimator=XGBRegressor(base_score=None, booster=None,\n",
      "                                    callbacks=None, colsample_bylevel=None,\n",
      "                                    colsample_bynode=None,\n",
      "                                    colsample_bytree=None, device=None,\n",
      "                                    early_stopping_rounds=None,\n",
      "                                    enable_categorical=False, eval_metric=None,\n",
      "                                    feature_types=None, gamma=None,\n",
      "                                    grow_policy=None, importance_type=None,\n",
      "                                    interaction_constraints=None,\n",
      "                                    learning_rate=None, m...\n",
      "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
      "                                    max_depth=None, max_leaves=None,\n",
      "                                    min_child_weight=None, missing=nan,\n",
      "                                    monotone_constraints=None,\n",
      "                                    multi_strategy=None, n_estimators=None,\n",
      "                                    n_jobs=None, num_parallel_tree=None,\n",
      "                                    random_state=None, ...),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'booster': ['gbtree', 'gblinear', 'dart'],\n",
      "                         'learning_rate': [0.001, 0.01, 0.1],\n",
      "                         'max_depth': [None, 1, 3, 5, 10, 20],\n",
      "                         'subsample': [0.5, 1]},\n",
      "             verbose=2), 'modelXGBFullurineFlav': GridSearchCV(cv=3,\n",
      "             estimator=XGBRegressor(base_score=None, booster=None,\n",
      "                                    callbacks=None, colsample_bylevel=None,\n",
      "                                    colsample_bynode=None,\n",
      "                                    colsample_bytree=None, device=None,\n",
      "                                    early_stopping_rounds=None,\n",
      "                                    enable_categorical=False, eval_metric=None,\n",
      "                                    feature_types=None, gamma=None,\n",
      "                                    grow_policy=None, importance_type=None,\n",
      "                                    interaction_constraints=None,\n",
      "                                    learning_rate=None, m...\n",
      "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
      "                                    max_depth=None, max_leaves=None,\n",
      "                                    min_child_weight=None, missing=nan,\n",
      "                                    monotone_constraints=None,\n",
      "                                    multi_strategy=None, n_estimators=None,\n",
      "                                    n_jobs=None, num_parallel_tree=None,\n",
      "                                    random_state=None, ...),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'booster': ['gbtree', 'gblinear', 'dart'],\n",
      "                         'learning_rate': [0.001, 0.01, 0.1],\n",
      "                         'max_depth': [None, 1, 3, 5, 10, 20],\n",
      "                         'subsample': [0.5, 1]},\n",
      "             verbose=2), 'modelXGBMeturineAnt': GridSearchCV(cv=3,\n",
      "             estimator=XGBRegressor(base_score=None, booster=None,\n",
      "                                    callbacks=None, colsample_bylevel=None,\n",
      "                                    colsample_bynode=None,\n",
      "                                    colsample_bytree=None, device=None,\n",
      "                                    early_stopping_rounds=None,\n",
      "                                    enable_categorical=False, eval_metric=None,\n",
      "                                    feature_types=None, gamma=None,\n",
      "                                    grow_policy=None, importance_type=None,\n",
      "                                    interaction_constraints=None,\n",
      "                                    learning_rate=None, m...\n",
      "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
      "                                    max_depth=None, max_leaves=None,\n",
      "                                    min_child_weight=None, missing=nan,\n",
      "                                    monotone_constraints=None,\n",
      "                                    multi_strategy=None, n_estimators=None,\n",
      "                                    n_jobs=None, num_parallel_tree=None,\n",
      "                                    random_state=None, ...),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'booster': ['gbtree', 'gblinear', 'dart'],\n",
      "                         'learning_rate': [0.001, 0.01, 0.1],\n",
      "                         'max_depth': [None, 1, 3, 5, 10, 20],\n",
      "                         'subsample': [0.5, 1]},\n",
      "             verbose=2), 'modelXGBFullurineAnt': GridSearchCV(cv=3,\n",
      "             estimator=XGBRegressor(base_score=None, booster=None,\n",
      "                                    callbacks=None, colsample_bylevel=None,\n",
      "                                    colsample_bynode=None,\n",
      "                                    colsample_bytree=None, device=None,\n",
      "                                    early_stopping_rounds=None,\n",
      "                                    enable_categorical=False, eval_metric=None,\n",
      "                                    feature_types=None, gamma=None,\n",
      "                                    grow_policy=None, importance_type=None,\n",
      "                                    interaction_constraints=None,\n",
      "                                    learning_rate=None, m...\n",
      "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
      "                                    max_depth=None, max_leaves=None,\n",
      "                                    min_child_weight=None, missing=nan,\n",
      "                                    monotone_constraints=None,\n",
      "                                    multi_strategy=None, n_estimators=None,\n",
      "                                    n_jobs=None, num_parallel_tree=None,\n",
      "                                    random_state=None, ...),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'booster': ['gbtree', 'gblinear', 'dart'],\n",
      "                         'learning_rate': [0.001, 0.01, 0.1],\n",
      "                         'max_depth': [None, 1, 3, 5, 10, 20],\n",
      "                         'subsample': [0.5, 1]},\n",
      "             verbose=2)}\n",
      "{'modelMLPMetplasmFlav': KerasRegressor(\n",
      "\tmodel=<keras.src.engine.sequential.Sequential object at 0x0000014F6D5A7B10>\n",
      "\tbuild_fn=None\n",
      "\twarm_start=False\n",
      "\trandom_state=None\n",
      "\toptimizer=<keras.src.optimizers.adam.Adam object at 0x0000014F6FDD5C90>\n",
      "\tloss=None\n",
      "\tmetrics=None\n",
      "\tbatch_size=10\n",
      "\tvalidation_batch_size=None\n",
      "\tverbose=0\n",
      "\tcallbacks=None\n",
      "\tvalidation_split=0.0\n",
      "\tshuffle=True\n",
      "\trun_eagerly=False\n",
      "\tepochs=100\n",
      "), 'modelMLPFullplasmFlav': KerasRegressor(\n",
      "\tmodel=<keras.src.engine.sequential.Sequential object at 0x0000014F737BCC50>\n",
      "\tbuild_fn=None\n",
      "\twarm_start=False\n",
      "\trandom_state=None\n",
      "\toptimizer=<keras.src.optimizers.adam.Adam object at 0x0000014F6D5EBD10>\n",
      "\tloss=None\n",
      "\tmetrics=None\n",
      "\tbatch_size=10\n",
      "\tvalidation_batch_size=None\n",
      "\tverbose=0\n",
      "\tcallbacks=None\n",
      "\tvalidation_split=0.0\n",
      "\tshuffle=True\n",
      "\trun_eagerly=False\n",
      "\tepochs=100\n",
      "), 'modelMLPMetplasmAnt': KerasRegressor(\n",
      "\tmodel=<keras.src.engine.sequential.Sequential object at 0x0000014F6D6EBDD0>\n",
      "\tbuild_fn=None\n",
      "\twarm_start=False\n",
      "\trandom_state=None\n",
      "\toptimizer=<keras.src.optimizers.adam.Adam object at 0x0000014F6C2AC0D0>\n",
      "\tloss=None\n",
      "\tmetrics=None\n",
      "\tbatch_size=10\n",
      "\tvalidation_batch_size=None\n",
      "\tverbose=0\n",
      "\tcallbacks=None\n",
      "\tvalidation_split=0.0\n",
      "\tshuffle=True\n",
      "\trun_eagerly=False\n",
      "\tepochs=100\n",
      "), 'modelMLPFullplasmAnt': KerasRegressor(\n",
      "\tmodel=<keras.src.engine.sequential.Sequential object at 0x0000014F74E4AE10>\n",
      "\tbuild_fn=None\n",
      "\twarm_start=False\n",
      "\trandom_state=None\n",
      "\toptimizer=<keras.src.optimizers.adam.Adam object at 0x0000014F6D56BB50>\n",
      "\tloss=None\n",
      "\tmetrics=None\n",
      "\tbatch_size=10\n",
      "\tvalidation_batch_size=None\n",
      "\tverbose=0\n",
      "\tcallbacks=None\n",
      "\tvalidation_split=0.0\n",
      "\tshuffle=True\n",
      "\trun_eagerly=False\n",
      "\tepochs=100\n",
      "), 'modelMLPMeturineFlav': KerasRegressor(\n",
      "\tmodel=<keras.src.engine.sequential.Sequential object at 0x0000014F750EB250>\n",
      "\tbuild_fn=None\n",
      "\twarm_start=False\n",
      "\trandom_state=None\n",
      "\toptimizer=<keras.src.optimizers.adam.Adam object at 0x0000014F6CE75010>\n",
      "\tloss=None\n",
      "\tmetrics=None\n",
      "\tbatch_size=10\n",
      "\tvalidation_batch_size=None\n",
      "\tverbose=0\n",
      "\tcallbacks=None\n",
      "\tvalidation_split=0.0\n",
      "\tshuffle=True\n",
      "\trun_eagerly=False\n",
      "\tepochs=100\n",
      "), 'modelMLPFullurineFlav': KerasRegressor(\n",
      "\tmodel=<keras.src.engine.sequential.Sequential object at 0x0000014F75232E90>\n",
      "\tbuild_fn=None\n",
      "\twarm_start=False\n",
      "\trandom_state=None\n",
      "\toptimizer=<keras.src.optimizers.adam.Adam object at 0x0000014F750C3010>\n",
      "\tloss=None\n",
      "\tmetrics=None\n",
      "\tbatch_size=10\n",
      "\tvalidation_batch_size=None\n",
      "\tverbose=0\n",
      "\tcallbacks=None\n",
      "\tvalidation_split=0.0\n",
      "\tshuffle=True\n",
      "\trun_eagerly=False\n",
      "\tepochs=100\n",
      "), 'modelMLPMeturineAnt': KerasRegressor(\n",
      "\tmodel=<keras.src.engine.sequential.Sequential object at 0x0000014F753429D0>\n",
      "\tbuild_fn=None\n",
      "\twarm_start=False\n",
      "\trandom_state=None\n",
      "\toptimizer=<keras.src.optimizers.adam.Adam object at 0x0000014F75100690>\n",
      "\tloss=None\n",
      "\tmetrics=None\n",
      "\tbatch_size=40\n",
      "\tvalidation_batch_size=None\n",
      "\tverbose=0\n",
      "\tcallbacks=None\n",
      "\tvalidation_split=0.0\n",
      "\tshuffle=True\n",
      "\trun_eagerly=False\n",
      "\tepochs=100\n",
      "), 'modelMLPFullurineAnt': KerasRegressor(\n",
      "\tmodel=<keras.src.engine.sequential.Sequential object at 0x0000014F754EB3D0>\n",
      "\tbuild_fn=None\n",
      "\twarm_start=False\n",
      "\trandom_state=None\n",
      "\toptimizer=<keras.src.optimizers.adam.Adam object at 0x0000014F751EF3D0>\n",
      "\tloss=None\n",
      "\tmetrics=None\n",
      "\tbatch_size=10\n",
      "\tvalidation_batch_size=None\n",
      "\tverbose=0\n",
      "\tcallbacks=None\n",
      "\tvalidation_split=0.0\n",
      "\tshuffle=True\n",
      "\trun_eagerly=False\n",
      "\tepochs=100\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "names = [\"resultsScores\", \"resultsModels\"]\n",
    "models = [\"RF\", \"XGB\", \"MLP\"]\n",
    "\n",
    "for i in [name+model for name in names for model in models]:\n",
    "    with open (i+\".pkl\", 'rb') as f:\n",
    "        i = pickle.load(f)\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectFromModel method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "starting df plasmFlav\n",
      "--------\n",
      "##### modelRFMetplasmFlav #####\n",
      "##### modelRFFullplasmFlav #####\n",
      "--------\n",
      "ended df\n",
      "--------\n",
      "--------\n",
      "starting df plasmAnt\n",
      "--------\n",
      "##### modelRFMetplasmAnt #####\n",
      "##### modelRFFullplasmAnt #####\n",
      "--------\n",
      "ended df\n",
      "--------\n",
      "--------\n",
      "starting df urineFlav\n",
      "--------\n",
      "##### modelRFMeturineFlav #####\n",
      "##### modelRFFullurineFlav #####\n",
      "--------\n",
      "ended df\n",
      "--------\n",
      "--------\n",
      "starting df urineAnt\n",
      "--------\n",
      "##### modelRFMeturineAnt #####\n",
      "##### modelRFFullurineAnt #####\n",
      "--------\n",
      "ended df\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def randomForestRegCV(X_train, y_train):\n",
    "    model = RandomForestRegressor()\n",
    "    param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "    }\n",
    "    grid_search = GridSearchCV(estimator = model, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_grid = grid_search.best_estimator_\n",
    "    return(best_grid)\n",
    "    \n",
    "def featureSelectionCustom(df, df_name, modelDict, MLmethod, met = True):\n",
    "\n",
    "    X_met, y_met, X_metTrain, X_metTest, y_metTrain, y_metTest, X_full, y_full, X_fullTrain, X_fullTest, y_fullTrain, y_fullTest = encodingSplitting(df)\n",
    "\n",
    "    if (met):\n",
    "        X_train, y_train, X_test, y_test = X_metTrain, y_metTrain, X_metTest, y_metTest\n",
    "        model_name = \"model\" +  MLmethod + \"Met\"+ df_name \n",
    "    else: \n",
    "        X_train, y_train, X_test, y_test = X_fullTrain, y_fullTrain, X_fullTest, y_fullTest\n",
    "        model_name = \"model\" +  MLmethod + \"Full\" + df_name\n",
    "    \n",
    "    # grid_search_testing = resultsModelsRF[\"modelRFFullplasmAnt\"] # model PF_met\n",
    "    \n",
    "\n",
    "    grid_search_testing = modelDict[model_name]\n",
    "\n",
    "    model = grid_search_testing.best_estimator_\n",
    "    print(\"##### \" + model_name + \" #####\")\n",
    "    thresholds = np.sort(model.feature_importances_)\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        # feature_idx = selection.get_support()\n",
    "        \n",
    "        # print(X_train.columns[feature_idx])\n",
    "        # print(\"threshold\" + str(thresh))\n",
    "        select_X_train = selection.transform(X_train)\n",
    "        # train model\n",
    "        selection_model = RandomForestRegressor() #randomForestRegCV(select_X_train, y_fullTrain)\n",
    "        selection_model.fit(select_X_train, y_train)\n",
    "        # eval model\n",
    "        select_X_test = selection.transform(X_test)\n",
    "        y_pred = selection_model.predict(select_X_test)\n",
    "        predictions = [value for value in y_pred]\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        result1 = pd.DataFrame({\"thresh\": thresh, \"n\":select_X_train.shape[1], \"MAE\":mae}, index = [30 - select_X_train.shape[1]])\n",
    "        results = pd.concat([results, result1])\n",
    "        # print(\"Thresh=%.3f, n=%d, MAE: %.4f\" % (thresh, select_X_train.shape[1], accuracy))\n",
    "\n",
    "    return (results)    \n",
    "\n",
    "paths = [\"plasmFlav_ord.csv\", \"plasmAnt_ord.csv\", \"urineFlav_ord.csv\", \"urineAnt_ord.csv\"]\n",
    "paths = [\"data/\" + s for s in paths]\n",
    "\n",
    "resultsFeatureSelectionRFMet = {}\n",
    "resultsFeatureSelectionRFFull = {}\n",
    "#resultsScoresXGB = {}\n",
    "\n",
    "for path in paths:\n",
    "     \n",
    "    df, df_name = fullRead(path, sep = \",\", anthro = True)\n",
    "   \n",
    "    print (\"--------\")\n",
    "    print (\"starting df \" + df_name)\n",
    "    print (\"--------\")\n",
    "   \n",
    "    resultsFeatureSelectionRFMet[\"featureSelectionRFMet{0}\".format(df_name)]= featureSelectionCustom(scaling(df), df_name, modelDict =  resultsModelsRF, MLmethod= \"RF\", met = True)\n",
    "    resultsFeatureSelectionRFFull[\"featureSelectionRFMet{0}\".format(df_name)]= featureSelectionCustom(scaling(df), df_name, modelDict =  resultsModelsRF, MLmethod= \"RF\", met = False)\n",
    "    \n",
    "    print (\"--------\")\n",
    "    print (\"ended df\")\n",
    "    print (\"--------\")\n",
    "    \n",
    "    #resultsModelsXGB[\"modelXGBFull{0}\".format(df_name)], resultsScoresXGB[\"modelXGBFull{0}\".format(df_name)] = XGBReg(scaling(df), df_name, met = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'featureSelectionRFMetplasmFlav':       thresh   n       MAE\n",
       " 13  0.006681  17  0.059640\n",
       " 14  0.009412  16  0.059257\n",
       " 15  0.010632  15  0.057757\n",
       " 16  0.012401  14  0.056980\n",
       " 17  0.021008  13  0.058249\n",
       " 18  0.021569  12  0.057027\n",
       " 19  0.052921  11  0.056726\n",
       " 20  0.055310  10  0.058157\n",
       " 21  0.056185   9  0.058601\n",
       " 22  0.073166   8  0.057695\n",
       " 23  0.075995   7  0.056417\n",
       " 24  0.086433   6  0.062026\n",
       " 25  0.087071   5  0.058898\n",
       " 26  0.093950   4  0.060619\n",
       " 27  0.098331   3  0.062081\n",
       " 28  0.101352   2  0.064049\n",
       " 29  0.137583   1  0.068315,\n",
       " 'featureSelectionRFMetplasmAnt':        thresh   n       MAE\n",
       " -1   0.000000  31  0.111678\n",
       "  0   0.007219  30  0.113253\n",
       "  1   0.008098  29  0.115496\n",
       "  2   0.010562  28  0.115267\n",
       "  3   0.014207  27  0.112872\n",
       "  4   0.015238  26  0.113640\n",
       "  5   0.020667  25  0.114611\n",
       "  6   0.021405  24  0.112578\n",
       "  7   0.022977  23  0.115560\n",
       "  8   0.024787  22  0.113786\n",
       "  9   0.026222  21  0.113813\n",
       "  10  0.027375  20  0.113637\n",
       "  11  0.027488  19  0.114491\n",
       "  12  0.029276  18  0.116005\n",
       "  13  0.029435  17  0.114918\n",
       "  14  0.029835  16  0.114228\n",
       "  15  0.029939  15  0.114003\n",
       "  16  0.030414  14  0.114007\n",
       "  17  0.031135  13  0.114465\n",
       "  18  0.033304  12  0.114519\n",
       "  19  0.034120  11  0.116146\n",
       "  20  0.035480  10  0.113390\n",
       "  21  0.036663   9  0.115194\n",
       "  22  0.038275   8  0.115827\n",
       "  23  0.042270   7  0.120896\n",
       "  24  0.043079   6  0.121181\n",
       "  25  0.045950   5  0.120563\n",
       "  26  0.053619   4  0.125070\n",
       "  27  0.059853   3  0.129649\n",
       "  28  0.076941   2  0.126493\n",
       "  29  0.094167   1  0.104955,\n",
       " 'featureSelectionRFMeturineFlav':       thresh   n       MAE\n",
       " 5   0.010811  25  0.062041\n",
       " 6   0.013768  24  0.060979\n",
       " 7   0.019190  23  0.062247\n",
       " 8   0.019468  22  0.062659\n",
       " 9   0.021000  21  0.061865\n",
       " 10  0.027064  20  0.062209\n",
       " 11  0.028619  19  0.062158\n",
       " 12  0.033874  18  0.063064\n",
       " 13  0.034923  17  0.063167\n",
       " 14  0.036004  16  0.062615\n",
       " 15  0.036298  15  0.062317\n",
       " 16  0.037913  14  0.062906\n",
       " 17  0.039536  13  0.065566\n",
       " 18  0.039594  12  0.063174\n",
       " 19  0.041437  11  0.064068\n",
       " 20  0.041767  10  0.062455\n",
       " 21  0.047357   9  0.062262\n",
       " 22  0.047910   8  0.062142\n",
       " 23  0.050643   7  0.063691\n",
       " 24  0.052707   6  0.066356\n",
       " 25  0.056071   5  0.066585\n",
       " 26  0.061221   4  0.066830\n",
       " 27  0.066271   3  0.060548\n",
       " 28  0.066408   2  0.061809\n",
       " 29  0.070144   1  0.068124,\n",
       " 'featureSelectionRFMeturineAnt':        thresh   n       MAE\n",
       " -3   0.011969  33  0.072854\n",
       " -2   0.012592  32  0.072878\n",
       " -1   0.013277  31  0.073205\n",
       "  0   0.014084  30  0.072530\n",
       "  1   0.014652  29  0.074969\n",
       "  2   0.017024  28  0.074830\n",
       "  3   0.018143  27  0.073617\n",
       "  4   0.018212  26  0.074550\n",
       "  5   0.022292  25  0.073704\n",
       "  6   0.023449  24  0.075149\n",
       "  7   0.023554  23  0.074548\n",
       "  8   0.023682  22  0.073681\n",
       "  9   0.023800  21  0.073283\n",
       "  10  0.023979  20  0.072521\n",
       "  11  0.026756  19  0.072981\n",
       "  12  0.027311  18  0.072315\n",
       "  13  0.028097  17  0.072610\n",
       "  14  0.029477  16  0.072992\n",
       "  15  0.030231  15  0.070148\n",
       "  16  0.030869  14  0.070601\n",
       "  17  0.032150  13  0.070880\n",
       "  18  0.032767  12  0.071284\n",
       "  19  0.034758  11  0.072003\n",
       "  20  0.038621  10  0.072430\n",
       "  21  0.039226   9  0.074768\n",
       "  22  0.041641   8  0.074176\n",
       "  23  0.043231   7  0.076835\n",
       "  24  0.044285   6  0.076251\n",
       "  25  0.046813   5  0.077481\n",
       "  26  0.049551   4  0.077867\n",
       "  27  0.052138   3  0.080782\n",
       "  28  0.053122   2  0.083653\n",
       "  29  0.058245   1  0.093084}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsFeatureSelectionRFMet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HE.G', 'N.G', 'Weight', 'BMI', 'Fat', 'Bpmin', 'Frec'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholdSelected = results.sort_values(by= \"MAE\", ascending = True).head(n=1)[\"thresh\"]\n",
    "\n",
    "# Si hay que reentrenar:\n",
    "\n",
    "\n",
    "\n",
    "# select features using threshold\n",
    "selection = SelectFromModel(model, threshold=thresholdSelected, prefit=True)\n",
    "feature_idx = selection.get_support()\n",
    "print(X_train.columns[feature_idx])\n",
    "select_X_train = selection.transform(X_train)\n",
    "# train model\n",
    "selection_model = RandomForestRegressor()\n",
    "selection_model.fit(select_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'if_delegate_has_method' from 'sklearn.utils.metaestimators' (c:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dres2\\Documents\\repositories\\thirdArt\\main.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39meli5\u001b[39;00m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meli5\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m PermutationImportance\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dres2/Documents/repositories/thirdArt/main.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m perm_base \u001b[39m=\u001b[39m PermutationImportance(modelMLPMet, random_state \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\eli5\\__init__.py:13\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mformatters\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     format_as_html,\n\u001b[0;32m      8\u001b[0m     format_html_styles,\n\u001b[0;32m      9\u001b[0m     format_as_text,\n\u001b[0;32m     10\u001b[0m     format_as_dict,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexplain\u001b[39;00m \u001b[39mimport\u001b[39;00m explain_weights, explain_prediction\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m explain_weights_sklearn, explain_prediction_sklearn\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtransform\u001b[39;00m \u001b[39mimport\u001b[39;00m transform_feature_names\n\u001b[0;32m     17\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\eli5\\sklearn\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexplain_weights\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     explain_weights_sklearn,\n\u001b[0;32m      5\u001b[0m     explain_linear_classifier_weights,\n\u001b[0;32m      6\u001b[0m     explain_linear_regressor_weights,\n\u001b[0;32m      7\u001b[0m     explain_rf_feature_importance,\n\u001b[0;32m      8\u001b[0m     explain_decision_tree,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexplain_prediction\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     explain_prediction_sklearn,\n\u001b[0;32m     12\u001b[0m     explain_prediction_linear_classifier,\n\u001b[0;32m     13\u001b[0m     explain_prediction_linear_regressor,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39munhashing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     InvertableHashingVectorizer,\n\u001b[0;32m     17\u001b[0m     FeatureUnhasher,\n\u001b[0;32m     18\u001b[0m     invert_hashing_and_fit,\n\u001b[0;32m     19\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\eli5\\sklearn\\explain_weights.py:78\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meli5\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransform\u001b[39;00m \u001b[39mimport\u001b[39;00m transform_feature_names\n\u001b[0;32m     74\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meli5\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_feature_importances\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     75\u001b[0m     get_feature_importances_filtered,\n\u001b[0;32m     76\u001b[0m     get_feature_importance_explanation,\n\u001b[0;32m     77\u001b[0m )\n\u001b[1;32m---> 78\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpermutation_importance\u001b[39;00m \u001b[39mimport\u001b[39;00m PermutationImportance\n\u001b[0;32m     81\u001b[0m LINEAR_CAVEATS \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     82\u001b[0m \u001b[39mCaveats:\u001b[39m\n\u001b[0;32m     83\u001b[0m \u001b[39m1. Be careful with features which are not\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39m   classification result for most examples.\u001b[39m\n\u001b[0;32m     91\u001b[0m \u001b[39m\"\"\"\u001b[39m\u001b[39m.\u001b[39mlstrip()\n\u001b[0;32m     93\u001b[0m HASHING_CAVEATS \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     94\u001b[0m \u001b[39mFeature names are restored from their hashes; this is not 100\u001b[39m\u001b[39m%\u001b[39m\u001b[39m precise\u001b[39m\n\u001b[0;32m     95\u001b[0m \u001b[39mbecause collisions are possible. For known collisions possible feature names\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mthe result is positive.\u001b[39m\n\u001b[0;32m    100\u001b[0m \u001b[39m\"\"\"\u001b[39m\u001b[39m.\u001b[39mlstrip()\n",
      "File \u001b[1;32mc:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\eli5\\sklearn\\permutation_importance.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m check_cv\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetaestimators\u001b[39;00m \u001b[39mimport\u001b[39;00m if_delegate_has_method\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m check_array, check_random_state\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     BaseEstimator,\n\u001b[0;32m     11\u001b[0m     MetaEstimatorMixin,\n\u001b[0;32m     12\u001b[0m     clone,\n\u001b[0;32m     13\u001b[0m     is_classifier\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'if_delegate_has_method' from 'sklearn.utils.metaestimators' (c:\\Users\\dres2\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py)"
     ]
    }
   ],
   "source": [
    "import eli5 \n",
    "from eli5.sklearn import PermutationImportance\n",
    "perm_base = PermutationImportance(modelMLPMet, random_state = 1).fit(X, y)\n",
    "eli5.show_weights(perm_base, feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0905\n",
       "                \n",
       "                    &plusmn; 0.0166\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Sex\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0336\n",
       "                \n",
       "                    &plusmn; 0.0154\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Sweetener\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.83%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0169\n",
       "                \n",
       "                    &plusmn; 0.0053\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Weight\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0153\n",
       "                \n",
       "                    &plusmn; 0.0060\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BMI\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0080\n",
       "                \n",
       "                    &plusmn; 0.0031\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Fat\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "                    &plusmn; 0.0025\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                CVRI\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0026\n",
       "                \n",
       "                    &plusmn; 0.0016\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Bpmin\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0026\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Bpmax\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0024\n",
       "                \n",
       "                    &plusmn; 0.0019\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                VA.GS\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.50%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0022\n",
       "                \n",
       "                    &plusmn; 0.0016\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                CA\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.55%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0021\n",
       "                \n",
       "                    &plusmn; 0.0022\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                VA.SS\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.62%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0020\n",
       "                \n",
       "                    &plusmn; 0.0028\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                VA.S\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0019\n",
       "                \n",
       "                    &plusmn; 0.0014\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                TFA.S\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                DHPAA.GS\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.98%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0013\n",
       "                \n",
       "                    &plusmn; 0.0016\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                CA.G\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.14%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0010\n",
       "                \n",
       "                    &plusmn; 0.0041\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                DHPAA.SS\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Total.CA\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.46%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                VA.GG\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                DHPAA.GG\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Total.TFA\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.53%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 8 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5 \n",
    "from eli5.sklearn import PermutationImportance\n",
    "perm_base = PermutationImportance(uwu.best_estimator_, random_state = 1).fit(X_fulltrain, y_fulltrain)\n",
    "eli5.show_weights(perm_base, feature_names = X_fulltrain.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full parameters gridsearch\n",
    "# DONT EXECUTE\n",
    "'''\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "weight_constraint = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, optimizer=optimizer, optimizer__learning_rate=learn_rate, optimizer__momentum=momentum,\n",
    "                  model__init_mode=init_mode, model__activation=activation, model__dropout_rate=dropout_rate, model__weight_constraint=weight_constraint)\n",
    "\n",
    "# get the model\n",
    "def get_model(n_inputs, n_outputs, dropout_rate, weight_constraint, activation=\"relu\", init_mode='uniform'):\n",
    "    model_nn = Sequential()\n",
    "    model_nn.add(Dense(64, input_shape=(X.shape[1],),activation=activation, kernel_initializer=init_mode, kernel_constraint=MaxNorm(weight_constraint)))\n",
    "    model_nn.add(Dropout(dropout_rate))\n",
    "    model_nn.add(Dense(32, activation=activation, kernel_initializer=init_mode))\n",
    "    model_nn.add(Dropout(dropout_rate))\n",
    "    model_nn.add(Dense(y.shape[1], activation='linear', kernel_initializer=init_mode))\n",
    "    return model_nn\n",
    " \n",
    "# evaluate a model using repeated k-fold cross-validation\n",
    "def evaluate_model(X, y):\n",
    " results = list()\n",
    " n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    " # define evaluation procedure\n",
    " cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# define modeld\n",
    " model_nn = KerasRegressor(model = get_model) #(n_inputs, n_outputs, activation=\"relu\", init_mode='uniform'))\n",
    " # fit model\n",
    " grid = GridSearchCV(estimator=model_nn, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    " grid_result = grid.fit(X_train, y_train) # evaluate model on test set\n",
    " mae = model_nn.evaluate(X_test, y_test)\n",
    " # store result\n",
    " print('>%.3f' % mae)\n",
    " results.append(mae)\n",
    " return results\n",
    " \n",
    "# evaluate model\n",
    "results = evaluate_model(X, y)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(results), std(results)))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
